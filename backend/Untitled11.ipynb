{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKk7uzBIg_dI"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CWJJ2vZzPemv",
        "outputId": "9818c721-753f-407f-c69d-82d37bb94531"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.57.3-py3-none-any.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets\n",
            "  Downloading datasets-4.4.1-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\n",
            "Collecting scikit-learn\n",
            "  Downloading scikit_learn-1.7.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
            "Collecting accelerate\n",
            "  Downloading accelerate-1.12.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting filelock (from transformers)\n",
            "  Downloading filelock-3.20.0-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting huggingface-hub<1.0,>=0.34.0 (from transformers)\n",
            "  Downloading huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting numpy>=1.17 (from transformers)\n",
            "  Downloading numpy-2.3.5-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting packaging>=20.0 (from transformers)\n",
            "  Downloading packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting pyyaml>=5.1 (from transformers)\n",
            "  Downloading pyyaml-6.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.4 kB)\n",
            "Collecting regex!=2019.12.17 (from transformers)\n",
            "  Downloading regex-2025.11.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests (from transformers)\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers)\n",
            "  Downloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting safetensors>=0.4.3 (from transformers)\n",
            "  Downloading safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Collecting tqdm>=4.27 (from transformers)\n",
            "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyarrow>=21.0.0 (from datasets)\n",
            "  Downloading pyarrow-22.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.2 kB)\n",
            "Collecting dill<0.4.1,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.4.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting pandas (from datasets)\n",
            "  Downloading pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx<1.0.0 (from datasets)\n",
            "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.6.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n",
            "Collecting multiprocess<0.70.19 (from datasets)\n",
            "  Downloading multiprocess-0.70.18-py312-none-any.whl.metadata (7.5 kB)\n",
            "Collecting fsspec<=2025.10.0,>=2023.1.0 (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2025.10.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting scipy>=1.8.0 (from scikit-learn)\n",
            "  Downloading scipy-1.16.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting joblib>=1.2.0 (from scikit-learn)\n",
            "  Downloading joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
            "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting psutil (from accelerate)\n",
            "  Downloading psutil-7.1.3-cp36-abi3-manylinux2010_x86_64.manylinux_2_12_x86_64.manylinux_2_28_x86_64.whl.metadata (23 kB)\n",
            "Collecting torch>=2.0.0 (from accelerate)\n",
            "  Downloading torch-2.9.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
            "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
            "  Downloading aiohttp-3.13.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (8.1 kB)\n",
            "Collecting anyio (from httpx<1.0.0->datasets)\n",
            "  Downloading anyio-4.12.0-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting certifi (from httpx<1.0.0->datasets)\n",
            "  Downloading certifi-2025.11.12-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting httpcore==1.* (from httpx<1.0.0->datasets)\n",
            "  Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting idna (from httpx<1.0.0->datasets)\n",
            "  Downloading idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting h11>=0.16 (from httpcore==1.*->httpx<1.0.0->datasets)\n",
            "  Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
            "Collecting typing-extensions>=3.7.4.3 (from huggingface-hub<1.0,>=0.34.0->transformers)\n",
            "  Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub<1.0,>=0.34.0->transformers)\n",
            "  Downloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting charset_normalizer<4,>=2 (from requests->transformers)\n",
            "  Downloading charset_normalizer-3.4.4-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (37 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests->transformers)\n",
            "  Downloading urllib3-2.6.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting setuptools (from torch>=2.0.0->accelerate)\n",
            "  Downloading setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting sympy>=1.13.3 (from torch>=2.0.0->accelerate)\n",
            "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting networkx>=2.5.1 (from torch>=2.0.0->accelerate)\n",
            "  Downloading networkx-3.6-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting jinja2 (from torch>=2.0.0->accelerate)\n",
            "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.10.2.21 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cublas-cu12==12.8.4.1 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.9.90 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cusparselt-cu12==0.7.1 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
            "Collecting nvidia-nccl-cu12==2.27.5 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
            "Collecting nvidia-nvshmem-cu12==3.3.20 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.8.90 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.8.93 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufile-cu12==1.13.1.3 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==3.5.1 (from torch>=2.0.0->accelerate)\n",
            "  Downloading triton-3.5.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting python-dateutil>=2.8.2 (from pandas->datasets)\n",
            "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting pytz>=2020.1 (from pandas->datasets)\n",
            "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tzdata>=2022.7 (from pandas->datasets)\n",
            "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
            "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
            "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting attrs>=17.3.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
            "  Downloading attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
            "  Downloading frozenlist-1.8.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (20 kB)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
            "  Downloading multidict-6.7.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
            "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
            "  Downloading propcache-0.4.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n",
            "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
            "  Downloading yarl-1.22.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.1/75.1 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting six>=1.5 (from python-dateutil>=2.8.2->pandas->datasets)\n",
            "  Downloading six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch>=2.0.0->accelerate)\n",
            "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2->torch>=2.0.0->accelerate)\n",
            "  Downloading markupsafe-3.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.7 kB)\n",
            "Downloading transformers-4.57.3-py3-none-any.whl (12.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-4.4.1-py3-none-any.whl (511 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m511.6/511.6 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading evaluate-0.4.6-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scikit_learn-1.7.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading accelerate-1.12.0-py3-none-any.whl (380 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m380.9/380.9 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.4.0-py3-none-any.whl (119 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.7/119.7 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2025.10.0-py3-none-any.whl (200 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.0/201.0 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.5/73.5 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m566.1/566.1 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading joblib-1.5.2-py3-none-any.whl (308 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m308.4/308.4 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.18-py312-none-any.whl (150 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.3/150.3 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.3.5-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading packaging-25.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.5/66.5 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-22.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (47.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyyaml-6.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (807 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m807.9/807.9 kB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading regex-2025.11.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (803 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.5/803.5 kB\u001b[0m \u001b[31m48.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (507 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.2/507.2 kB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.16.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (35.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.7/35.7 MB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
            "Downloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m70.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.9.1-cp312-cp312-manylinux_2_28_x86_64.whl (899.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m899.7/899.7 MB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m93.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m68.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m706.8/706.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.2/287.2 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.3/322.3 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (124.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.7/124.7 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.5.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (170.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.5/170.5 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filelock-3.20.0-py3-none-any.whl (16 kB)\n",
            "Downloading pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m103.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading psutil-7.1.3-cp36-abi3-manylinux2010_x86_64.manylinux_2_12_x86_64.manylinux_2_28_x86_64.whl (263 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m263.3/263.3 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.6.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (193 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.9/193.9 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiohttp-3.13.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m57.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading certifi-2025.11.12-py3-none-any.whl (159 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.4/159.4 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading charset_normalizer-3.4.4-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (153 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.5/153.5 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m69.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-3.11-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.0/71.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading networkx-3.6-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m61.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.9/229.9 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m509.2/509.2 kB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m91.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m347.8/347.8 kB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading urllib3-2.6.0-py3-none-any.whl (131 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.1/131.1 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading anyio-4.12.0-py3-none-any.whl (113 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.4/113.4 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.9/134.9 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m53.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
            "Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
            "Downloading attrs-25.4.0-py3-none-any.whl (67 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading frozenlist-1.8.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (242 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.4/242.4 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
            "Downloading markupsafe-3.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (22 kB)\n",
            "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multidict-6.7.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (256 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m256.1/256.1 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading propcache-0.4.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (221 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m221.6/221.6 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading yarl-1.22.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (377 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m377.3/377.3 kB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytz, nvidia-cusparselt-cu12, mpmath, xxhash, urllib3, tzdata, typing-extensions, triton, tqdm, threadpoolctl, sympy, six, setuptools, safetensors, regex, pyyaml, pyarrow, psutil, propcache, packaging, nvidia-nvtx-cu12, nvidia-nvshmem-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, multidict, MarkupSafe, joblib, idna, hf-xet, h11, fsspec, frozenlist, filelock, dill, charset_normalizer, certifi, attrs, aiohappyeyeballs, yarl, scipy, requests, python-dateutil, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, multiprocess, jinja2, httpcore, anyio, aiosignal, scikit-learn, pandas, nvidia-cusolver-cu12, huggingface-hub, httpx, aiohttp, torch, tokenizers, transformers, datasets, accelerate, evaluate\n",
            "  Attempting uninstall: pytz\n",
            "    Found existing installation: pytz 2025.2\n",
            "    Uninstalling pytz-2025.2:\n",
            "      Successfully uninstalled pytz-2025.2\n",
            "  Attempting uninstall: nvidia-cusparselt-cu12\n",
            "    Found existing installation: nvidia-cusparselt-cu12 0.7.1\n",
            "    Uninstalling nvidia-cusparselt-cu12-0.7.1:\n",
            "      Successfully uninstalled nvidia-cusparselt-cu12-0.7.1\n",
            "  Attempting uninstall: mpmath\n",
            "    Found existing installation: mpmath 1.3.0\n",
            "    Uninstalling mpmath-1.3.0:\n",
            "      Successfully uninstalled mpmath-1.3.0\n",
            "  Attempting uninstall: xxhash\n",
            "    Found existing installation: xxhash 3.6.0\n",
            "    Uninstalling xxhash-3.6.0:\n",
            "      Successfully uninstalled xxhash-3.6.0\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.5.0\n",
            "    Uninstalling urllib3-2.5.0:\n",
            "      Successfully uninstalled urllib3-2.5.0\n",
            "  Attempting uninstall: tzdata\n",
            "    Found existing installation: tzdata 2025.2\n",
            "    Uninstalling tzdata-2025.2:\n",
            "      Successfully uninstalled tzdata-2025.2\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.15.0\n",
            "    Uninstalling typing_extensions-4.15.0:\n",
            "      Successfully uninstalled typing_extensions-4.15.0\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.5.0\n",
            "    Uninstalling triton-3.5.0:\n",
            "      Successfully uninstalled triton-3.5.0\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.67.1\n",
            "    Uninstalling tqdm-4.67.1:\n",
            "      Successfully uninstalled tqdm-4.67.1\n",
            "  Attempting uninstall: threadpoolctl\n",
            "    Found existing installation: threadpoolctl 3.6.0\n",
            "    Uninstalling threadpoolctl-3.6.0:\n",
            "      Successfully uninstalled threadpoolctl-3.6.0\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.14.0\n",
            "    Uninstalling sympy-1.14.0:\n",
            "      Successfully uninstalled sympy-1.14.0\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.17.0\n",
            "    Uninstalling six-1.17.0:\n",
            "      Successfully uninstalled six-1.17.0\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 75.2.0\n",
            "    Uninstalling setuptools-75.2.0:\n",
            "      Successfully uninstalled setuptools-75.2.0\n",
            "  Attempting uninstall: safetensors\n",
            "    Found existing installation: safetensors 0.7.0\n",
            "    Uninstalling safetensors-0.7.0:\n",
            "      Successfully uninstalled safetensors-0.7.0\n",
            "  Attempting uninstall: regex\n",
            "    Found existing installation: regex 2025.11.3\n",
            "    Uninstalling regex-2025.11.3:\n",
            "      Successfully uninstalled regex-2025.11.3\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 6.0.3\n",
            "    Uninstalling PyYAML-6.0.3:\n",
            "      Successfully uninstalled PyYAML-6.0.3\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 18.1.0\n",
            "    Uninstalling pyarrow-18.1.0:\n",
            "      Successfully uninstalled pyarrow-18.1.0\n",
            "  Attempting uninstall: psutil\n",
            "    Found existing installation: psutil 5.9.5\n",
            "    Uninstalling psutil-5.9.5:\n",
            "      Successfully uninstalled psutil-5.9.5\n",
            "  Attempting uninstall: propcache\n",
            "    Found existing installation: propcache 0.4.1\n",
            "    Uninstalling propcache-0.4.1:\n",
            "      Successfully uninstalled propcache-0.4.1\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 25.0\n",
            "    Uninstalling packaging-25.0:\n",
            "      Successfully uninstalled packaging-25.0\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.6.77\n",
            "    Uninstalling nvidia-nvtx-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-nvshmem-cu12\n",
            "    Found existing installation: nvidia-nvshmem-cu12 3.3.20\n",
            "    Uninstalling nvidia-nvshmem-cu12-3.3.20:\n",
            "      Successfully uninstalled nvidia-nvshmem-cu12-3.3.20\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.6.85\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.6.85:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.6.85\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.27.5\n",
            "    Uninstalling nvidia-nccl-cu12-2.27.5:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.27.5\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
            "    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
            "  Attempting uninstall: nvidia-cufile-cu12\n",
            "    Found existing installation: nvidia-cufile-cu12 1.11.1.6\n",
            "    Uninstalling nvidia-cufile-cu12-1.11.1.6:\n",
            "      Successfully uninstalled nvidia-cufile-cu12-1.11.1.6\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n",
            "    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.6\n",
            "    Uninstalling networkx-3.6:\n",
            "      Successfully uninstalled networkx-3.6\n",
            "  Attempting uninstall: multidict\n",
            "    Found existing installation: multidict 6.7.0\n",
            "    Uninstalling multidict-6.7.0:\n",
            "      Successfully uninstalled multidict-6.7.0\n",
            "  Attempting uninstall: MarkupSafe\n",
            "    Found existing installation: MarkupSafe 3.0.3\n",
            "    Uninstalling MarkupSafe-3.0.3:\n",
            "      Successfully uninstalled MarkupSafe-3.0.3\n",
            "  Attempting uninstall: joblib\n",
            "    Found existing installation: joblib 1.5.2\n",
            "    Uninstalling joblib-1.5.2:\n",
            "      Successfully uninstalled joblib-1.5.2\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.11\n",
            "    Uninstalling idna-3.11:\n",
            "      Successfully uninstalled idna-3.11\n",
            "  Attempting uninstall: hf-xet\n",
            "    Found existing installation: hf-xet 1.2.0\n",
            "    Uninstalling hf-xet-1.2.0:\n",
            "      Successfully uninstalled hf-xet-1.2.0\n",
            "  Attempting uninstall: h11\n",
            "    Found existing installation: h11 0.16.0\n",
            "    Uninstalling h11-0.16.0:\n",
            "      Successfully uninstalled h11-0.16.0\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.0\n",
            "    Uninstalling fsspec-2025.3.0:\n",
            "      Successfully uninstalled fsspec-2025.3.0\n",
            "  Attempting uninstall: frozenlist\n",
            "    Found existing installation: frozenlist 1.8.0\n",
            "    Uninstalling frozenlist-1.8.0:\n",
            "      Successfully uninstalled frozenlist-1.8.0\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.20.0\n",
            "    Uninstalling filelock-3.20.0:\n",
            "      Successfully uninstalled filelock-3.20.0\n",
            "  Attempting uninstall: dill\n",
            "    Found existing installation: dill 0.3.8\n",
            "    Uninstalling dill-0.3.8:\n",
            "      Successfully uninstalled dill-0.3.8\n",
            "  Attempting uninstall: charset_normalizer\n",
            "    Found existing installation: charset-normalizer 3.4.4\n",
            "    Uninstalling charset-normalizer-3.4.4:\n",
            "      Successfully uninstalled charset-normalizer-3.4.4\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2025.11.12\n",
            "    Uninstalling certifi-2025.11.12:\n",
            "      Successfully uninstalled certifi-2025.11.12\n",
            "  Attempting uninstall: attrs\n",
            "    Found existing installation: attrs 25.4.0\n",
            "    Uninstalling attrs-25.4.0:\n",
            "      Successfully uninstalled attrs-25.4.0\n",
            "  Attempting uninstall: aiohappyeyeballs\n",
            "    Found existing installation: aiohappyeyeballs 2.6.1\n",
            "    Uninstalling aiohappyeyeballs-2.6.1:\n",
            "      Successfully uninstalled aiohappyeyeballs-2.6.1\n",
            "  Attempting uninstall: yarl\n",
            "    Found existing installation: yarl 1.22.0\n",
            "    Uninstalling yarl-1.22.0:\n",
            "      Successfully uninstalled yarl-1.22.0\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.16.3\n",
            "    Uninstalling scipy-1.16.3:\n",
            "      Successfully uninstalled scipy-1.16.3\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.4\n",
            "    Uninstalling requests-2.32.4:\n",
            "      Successfully uninstalled requests-2.32.4\n",
            "  Attempting uninstall: python-dateutil\n",
            "    Found existing installation: python-dateutil 2.9.0.post0\n",
            "    Uninstalling python-dateutil-2.9.0.post0:\n",
            "      Successfully uninstalled python-dateutil-2.9.0.post0\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
            "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.10.2.21\n",
            "    Uninstalling nvidia-cudnn-cu12-9.10.2.21:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.10.2.21\n",
            "  Attempting uninstall: multiprocess\n",
            "    Found existing installation: multiprocess 0.70.16\n",
            "    Uninstalling multiprocess-0.70.16:\n",
            "      Successfully uninstalled multiprocess-0.70.16\n",
            "  Attempting uninstall: jinja2\n",
            "    Found existing installation: Jinja2 3.1.6\n",
            "    Uninstalling Jinja2-3.1.6:\n",
            "      Successfully uninstalled Jinja2-3.1.6\n",
            "  Attempting uninstall: httpcore\n",
            "    Found existing installation: httpcore 1.0.9\n",
            "    Uninstalling httpcore-1.0.9:\n",
            "      Successfully uninstalled httpcore-1.0.9\n",
            "  Attempting uninstall: anyio\n",
            "    Found existing installation: anyio 4.11.0\n",
            "    Uninstalling anyio-4.11.0:\n",
            "      Successfully uninstalled anyio-4.11.0\n",
            "  Attempting uninstall: aiosignal\n",
            "    Found existing installation: aiosignal 1.4.0\n",
            "    Uninstalling aiosignal-1.4.0:\n",
            "      Successfully uninstalled aiosignal-1.4.0\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.6.1\n",
            "    Uninstalling scikit-learn-1.6.1:\n",
            "      Successfully uninstalled scikit-learn-1.6.1\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
            "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.36.0\n",
            "    Uninstalling huggingface-hub-0.36.0:\n",
            "      Successfully uninstalled huggingface-hub-0.36.0\n",
            "  Attempting uninstall: httpx\n",
            "    Found existing installation: httpx 0.28.1\n",
            "    Uninstalling httpx-0.28.1:\n",
            "      Successfully uninstalled httpx-0.28.1\n",
            "  Attempting uninstall: aiohttp\n",
            "    Found existing installation: aiohttp 3.13.2\n",
            "    Uninstalling aiohttp-3.13.2:\n",
            "      Successfully uninstalled aiohttp-3.13.2\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.9.0+cu126\n",
            "    Uninstalling torch-2.9.0+cu126:\n",
            "      Successfully uninstalled torch-2.9.0+cu126\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.22.1\n",
            "    Uninstalling tokenizers-0.22.1:\n",
            "      Successfully uninstalled tokenizers-0.22.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.57.2\n",
            "    Uninstalling transformers-4.57.2:\n",
            "      Successfully uninstalled transformers-4.57.2\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 4.0.0\n",
            "    Uninstalling datasets-4.0.0:\n",
            "      Successfully uninstalled datasets-4.0.0\n",
            "  Attempting uninstall: accelerate\n",
            "    Found existing installation: accelerate 1.12.0\n",
            "    Uninstalling accelerate-1.12.0:\n",
            "      Successfully uninstalled accelerate-1.12.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.3 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
            "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.3.5 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.5 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.5 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.5 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.5 which is incompatible.\n",
            "torchaudio 2.9.0+cu126 requires torch==2.9.0, but you have torch 2.9.1 which is incompatible.\n",
            "torchvision 0.24.0+cu126 requires torch==2.9.0, but you have torch 2.9.1 which is incompatible.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.10.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed MarkupSafe-3.0.3 accelerate-1.12.0 aiohappyeyeballs-2.6.1 aiohttp-3.13.2 aiosignal-1.4.0 anyio-4.12.0 attrs-25.4.0 certifi-2025.11.12 charset_normalizer-3.4.4 datasets-4.4.1 dill-0.4.0 evaluate-0.4.6 filelock-3.20.0 frozenlist-1.8.0 fsspec-2025.10.0 h11-0.16.0 hf-xet-1.2.0 httpcore-1.0.9 httpx-0.28.1 huggingface-hub-0.36.0 idna-3.11 jinja2-3.1.6 joblib-1.5.2 mpmath-1.3.0 multidict-6.7.0 multiprocess-0.70.18 networkx-3.6 numpy-2.3.5 nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cudnn-cu12-9.10.2.21 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-cusparselt-cu12-0.7.1 nvidia-nccl-cu12-2.27.5 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvshmem-cu12-3.3.20 nvidia-nvtx-cu12-12.8.90 packaging-25.0 pandas-2.3.3 propcache-0.4.1 psutil-7.1.3 pyarrow-22.0.0 python-dateutil-2.9.0.post0 pytz-2025.2 pyyaml-6.0.3 regex-2025.11.3 requests-2.32.5 safetensors-0.7.0 scikit-learn-1.7.2 scipy-1.16.3 setuptools-80.9.0 six-1.17.0 sympy-1.14.0 threadpoolctl-3.6.0 tokenizers-0.22.1 torch-2.9.1 tqdm-4.67.1 transformers-4.57.3 triton-3.5.1 typing-extensions-4.15.0 tzdata-2025.2 urllib3-2.6.0 xxhash-3.6.0 yarl-1.22.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "2e4ed088c3a449a3adbc549d39080e01",
              "pip_warning": {
                "packages": [
                  "_distutils_hack",
                  "certifi",
                  "dateutil",
                  "numpy",
                  "packaging",
                  "psutil",
                  "six"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install --force-reinstall transformers datasets evaluate scikit-learn accelerate --no-build-isolation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yEJBMuFvQWf0",
        "outputId": "9b9f9df1-8c3d-415d-adfd-b85339aedbab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: torch 2.9.1\n",
            "Uninstalling torch-2.9.1:\n",
            "  Successfully uninstalled torch-2.9.1\n",
            "Found existing installation: torchvision 0.24.0+cu126\n",
            "Uninstalling torchvision-0.24.0+cu126:\n",
            "  Successfully uninstalled torchvision-0.24.0+cu126\n",
            "Found existing installation: torchaudio 2.9.0+cu126\n",
            "Uninstalling torchaudio-2.9.0+cu126:\n",
            "  Successfully uninstalled torchaudio-2.9.0+cu126\n",
            "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
            "Collecting torch==2.4.0\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torch-2.4.0%2Bcu121-cp312-cp312-linux_x86_64.whl (799.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m799.0/799.0 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.19.0\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torchvision-0.19.0%2Bcu121-cp312-cp312-linux_x86_64.whl (7.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m114.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchaudio==2.4.0\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.4.0%2Bcu121-cp312-cp312-linux_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m114.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0) (4.15.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0) (1.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0) (2025.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0) (80.9.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m74.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m52.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m78.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m720.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.20.5 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==3.0.0 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/triton-3.0.0-1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision==0.19.0) (2.3.5)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision==0.19.0) (11.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.4.0) (12.8.93)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.4.0) (3.0.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch==2.4.0) (1.3.0)\n",
            "Installing collected packages: triton, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.5.1\n",
            "    Uninstalling triton-3.5.1:\n",
            "      Successfully uninstalled triton-3.5.1\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.8.90\n",
            "    Uninstalling nvidia-nvtx-cu12-12.8.90:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.8.90\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.27.5\n",
            "    Uninstalling nvidia-nccl-cu12-2.27.5:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.27.5\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.8.93\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.8.93:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.9.90\n",
            "    Uninstalling nvidia-curand-cu12-10.3.9.90:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.9.90\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.3.3.83\n",
            "    Uninstalling nvidia-cufft-cu12-11.3.3.83:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.8.90\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.8.90:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.8.90\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.8.93\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.8.93:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.8.93\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.8.90\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.8.90:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.8.90\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.8.4.1\n",
            "    Uninstalling nvidia-cublas-cu12-12.8.4.1:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.7.3.90\n",
            "    Uninstalling nvidia-cusolver-cu12-11.7.3.90:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.7.3.90\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.10.2.21\n",
            "    Uninstalling nvidia-cudnn-cu12-9.10.2.21:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.10.2.21\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvtx-cu12-12.1.105 torch-2.4.0+cu121 torchaudio-2.4.0+cu121 torchvision-0.19.0+cu121 triton-3.0.0\n",
            "Collecting causal-conv1d==1.4.0\n",
            "  Downloading causal_conv1d-1.4.0.tar.gz (9.3 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from causal-conv1d==1.4.0) (2.4.0+cu121)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from causal-conv1d==1.4.0) (25.0)\n",
            "Collecting ninja (from causal-conv1d==1.4.0)\n",
            "  Downloading ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->causal-conv1d==1.4.0) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch->causal-conv1d==1.4.0) (4.15.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch->causal-conv1d==1.4.0) (1.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->causal-conv1d==1.4.0) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->causal-conv1d==1.4.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->causal-conv1d==1.4.0) (2025.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->causal-conv1d==1.4.0) (80.9.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch->causal-conv1d==1.4.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch->causal-conv1d==1.4.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch->causal-conv1d==1.4.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.12/dist-packages (from torch->causal-conv1d==1.4.0) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.12/dist-packages (from torch->causal-conv1d==1.4.0) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.12/dist-packages (from torch->causal-conv1d==1.4.0) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.12/dist-packages (from torch->causal-conv1d==1.4.0) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.12/dist-packages (from torch->causal-conv1d==1.4.0) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.12/dist-packages (from torch->causal-conv1d==1.4.0) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.12/dist-packages (from torch->causal-conv1d==1.4.0) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch->causal-conv1d==1.4.0) (12.1.105)\n",
            "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.12/dist-packages (from torch->causal-conv1d==1.4.0) (3.0.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->causal-conv1d==1.4.0) (12.8.93)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->causal-conv1d==1.4.0) (3.0.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch->causal-conv1d==1.4.0) (1.3.0)\n",
            "Downloading ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (180 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m180.7/180.7 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: causal-conv1d\n",
            "  Building wheel for causal-conv1d (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for causal-conv1d: filename=causal_conv1d-1.4.0-cp312-cp312-linux_x86_64.whl size=104884589 sha256=70c6d91d00c625d750b83c9c4bdd0bd395c61aff9baa8c0d58e0a33dabbe3b4e\n",
            "  Stored in directory: /root/.cache/pip/wheels/3a/bd/04/a4893fd5ad69a02f55b49f04dc1dbbd7c439332db7895f62ff\n",
            "Successfully built causal-conv1d\n",
            "Installing collected packages: ninja, causal-conv1d\n",
            "Successfully installed causal-conv1d-1.4.0 ninja-1.13.0\n",
            "Collecting mamba-ssm==2.2.2\n",
            "  Downloading mamba_ssm-2.2.2.tar.gz (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from mamba-ssm==2.2.2) (2.4.0+cu121)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from mamba-ssm==2.2.2) (25.0)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.12/dist-packages (from mamba-ssm==2.2.2) (1.13.0)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (from mamba-ssm==2.2.2) (0.8.1)\n",
            "Requirement already satisfied: triton in /usr/local/lib/python3.12/dist-packages (from mamba-ssm==2.2.2) (3.0.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (from mamba-ssm==2.2.2) (4.57.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->mamba-ssm==2.2.2) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch->mamba-ssm==2.2.2) (4.15.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch->mamba-ssm==2.2.2) (1.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->mamba-ssm==2.2.2) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->mamba-ssm==2.2.2) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->mamba-ssm==2.2.2) (2025.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->mamba-ssm==2.2.2) (80.9.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch->mamba-ssm==2.2.2) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch->mamba-ssm==2.2.2) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch->mamba-ssm==2.2.2) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.12/dist-packages (from torch->mamba-ssm==2.2.2) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.12/dist-packages (from torch->mamba-ssm==2.2.2) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.12/dist-packages (from torch->mamba-ssm==2.2.2) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.12/dist-packages (from torch->mamba-ssm==2.2.2) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.12/dist-packages (from torch->mamba-ssm==2.2.2) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.12/dist-packages (from torch->mamba-ssm==2.2.2) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.12/dist-packages (from torch->mamba-ssm==2.2.2) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch->mamba-ssm==2.2.2) (12.1.105)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->mamba-ssm==2.2.2) (12.8.93)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers->mamba-ssm==2.2.2) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers->mamba-ssm==2.2.2) (2.3.5)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers->mamba-ssm==2.2.2) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers->mamba-ssm==2.2.2) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers->mamba-ssm==2.2.2) (2.32.5)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers->mamba-ssm==2.2.2) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers->mamba-ssm==2.2.2) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers->mamba-ssm==2.2.2) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers->mamba-ssm==2.2.2) (1.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->mamba-ssm==2.2.2) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers->mamba-ssm==2.2.2) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers->mamba-ssm==2.2.2) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers->mamba-ssm==2.2.2) (2.6.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers->mamba-ssm==2.2.2) (2025.11.12)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch->mamba-ssm==2.2.2) (1.3.0)\n",
            "Building wheels for collected packages: mamba-ssm\n",
            "  Building wheel for mamba-ssm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mamba-ssm: filename=mamba_ssm-2.2.2-cp312-cp312-linux_x86_64.whl size=324005633 sha256=f4cf06585ac28c783dbe6fe357c64218415af3665c3c06106be8f86dab69b2a8\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/b8/99/4112d82fe2a9458dd194c3ff54c43a14a8594c8f90cf16046f\n",
            "Successfully built mamba-ssm\n",
            "Installing collected packages: mamba-ssm\n",
            "Successfully installed mamba-ssm-2.2.2\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall -y torch torchvision torchaudio\n",
        "!pip install torch==2.4.0 torchvision==0.19.0 torchaudio==2.4.0 --index-url https://download.pytorch.org/whl/cu121\n",
        "!pip install causal-conv1d==1.4.0 && pip install mamba-ssm==2.2.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "vQUgRszTwPQt",
        "outputId": "6e682d66-2f8a-4820-ec16-8eadbba0cfd9"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3101549123.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"kuleshov-group/caduceus-ps_seqlen-131k_d_model-256_n_layer-16\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mbackbone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"kuleshov-group/caduceus-ps_seqlen-131k_d_model-256_n_layer-16\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/auto/tokenization_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1115\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m                 \u001b[0mupstream_repo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1117\u001b[0;31m             trust_remote_code = resolve_trust_remote_code(\n\u001b[0m\u001b[1;32m   1118\u001b[0m                 \u001b[0mtrust_remote_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_local_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_remote_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupstream_repo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/dynamic_module_utils.py\u001b[0m in \u001b[0;36mresolve_trust_remote_code\u001b[0;34m(trust_remote_code, model_name, has_local_code, has_remote_code, error_message, upstream_repo)\u001b[0m\n\u001b[1;32m    755\u001b[0m                 \u001b[0msignal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malarm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTIME_OUT_REMOTE_CODE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0mtrust_remote_code\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m                     answer = input(\n\u001b[0m\u001b[1;32m    758\u001b[0m                         \u001b[0;34mf\"{error_message} You can inspect the repository content at https://hf.co/{model_name}.\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m                         \u001b[0;34mf\"You can avoid this prompt in future by passing the argument `trust_remote_code=True`.\\n\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"kuleshov-group/caduceus-ps_seqlen-131k_d_model-256_n_layer-16\")\n",
        "backbone = AutoModel.from_pretrained(\"kuleshov-group/caduceus-ps_seqlen-131k_d_model-256_n_layer-16\").to(device)\n",
        "\n",
        "class BinaryDiseaseClassifier(nn.Module):\n",
        "    def ___init___(self, backbone, hidden_size=512):\n",
        "        super().___init___()\n",
        "        self.backbone = backbone\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(hidden_size, hidden_size // 2),\n",
        "            nn.LayerNorm(hidden_size // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(hidden_size // 2, hidden_size // 4),\n",
        "            nn.LayerNorm(hidden_size // 4),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(hidden_size // 4, 2)\n",
        "        )\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.backbone(input_ids)\n",
        "        hidden = outputs.last_hidden_state if hasattr(outputs, 'last_hidden_state') else outputs[0]\n",
        "        mask_expanded = attention_mask.unsqueeze(-1).expand(hidden.size()).float()\n",
        "        pooled = torch.sum(hidden * mask_expanded, 1) / torch.clamp(mask_expanded.sum(1), min=1e-9)\n",
        "        return self.classifier(self.dropout(pooled))\n",
        "\n",
        "model = BinaryDiseaseClassifier(backbone).to(device)\n",
        "model.load_state_dict(torch.load('caduceus_binary_final.pth', map_location=device))\n",
        "model.eval()\n",
        "\n",
        "def predict(sequence):\n",
        "    encoding = tokenizer(sequence[:512], truncation=True, padding='max_length', max_length=512, return_tensors='pt')\n",
        "    input_ids = encoding['input_ids'].to(device)\n",
        "    attention_mask = (input_ids != 0).long()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        logits = model(input_ids, attention_mask)\n",
        "        prob = torch.softmax(logits, dim=1)[0, 1].item()\n",
        "        pred = 1 if prob > 0.5 else 0\n",
        "    return \"POSITIVE\" if pred == 1 else \"NEGATIVE\", f\"{prob*100:.1f}%\"\n",
        "\n",
        "sequence = input(\"Enter DNA sequence: \")\n",
        "result, confidence = predict(sequence)\n",
        "print(f\"\\nResult: {result} (Confidence: {confidence})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "IyHpUR0f_ZI9",
        "outputId": "ba35ae26-a155-4d8e-ac81-e45b2449cf35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The repository kuleshov-group/caduceus-ps_seqlen-131k_d_model-256_n_layer-16 contains custom code which must be executed to correctly load the model. You can inspect the repository content at https://hf.co/kuleshov-group/caduceus-ps_seqlen-131k_d_model-256_n_layer-16 .\n",
            " You can inspect the repository content at https://hf.co/kuleshov-group/caduceus-ps_seqlen-131k_d_model-256_n_layer-16.\n",
            "You can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n",
            "\n",
            "Do you wish to run the custom code? [y/N] y\n",
            "The repository kuleshov-group/caduceus-ps_seqlen-131k_d_model-256_n_layer-16 contains custom code which must be executed to correctly load the model. You can inspect the repository content at https://hf.co/kuleshov-group/caduceus-ps_seqlen-131k_d_model-256_n_layer-16 .\n",
            " You can inspect the repository content at https://hf.co/kuleshov-group/caduceus-ps_seqlen-131k_d_model-256_n_layer-16.\n",
            "You can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n",
            "\n",
            "Do you wish to run the custom code? [y/N] y\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-169594151.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(\"caduceus_binary_final.pth\", map_location=device))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter DNA sequence: GCTTCACGTGTACCATGTTCCCGGCGGCCTCCTCGAAGGGCCTGTGCGGCTGCCGGCCCAGCTCCCGCAGGCTGCACAGCTTGGGCAGCCAGGTCCACGAG\n",
            "\n",
            "Result: NEGATIVE (Confidence: 49.1%)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    \"kuleshov-group/caduceus-ps_seqlen-131k_d_model-256_n_layer-16\"\n",
        ")\n",
        "\n",
        "backbone = AutoModel.from_pretrained(\n",
        "    \"kuleshov-group/caduceus-ps_seqlen-131k_d_model-256_n_layer-16\"\n",
        ").to(device)\n",
        "\n",
        "\n",
        "# ======================================================\n",
        "# 🔥 FIXED CLASSIFIER (MATCHES CHECKPOINT SHAPES EXACTLY)\n",
        "# ======================================================\n",
        "class BinaryDiseaseClassifier(nn.Module):\n",
        "    def ___init___(self, backbone):\n",
        "        super().___init___()\n",
        "        self.backbone = backbone\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(512, 256),     \n",
        "            nn.LayerNorm(256),        \n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "\n",
        "            nn.Linear(256, 128),      \n",
        "            nn.LayerNorm(128),        \n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "\n",
        "            nn.Linear(128, 2)         \n",
        "        )\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.backbone(input_ids)\n",
        "        hidden = outputs.last_hidden_state if hasattr(outputs, 'last_hidden_state') else outputs[0]\n",
        "\n",
        "        mask_expanded = attention_mask.unsqueeze(-1).expand(hidden.size()).float()\n",
        "        pooled = torch.sum(hidden * mask_expanded, 1) / torch.clamp(mask_expanded.sum(1), min=1e-9)\n",
        "\n",
        "        return self.classifier(self.dropout(pooled))\n",
        "\n",
        "\n",
        "model = BinaryDiseaseClassifier(backbone).to(device)\n",
        "model.load_state_dict(torch.load(\"caduceus_binary_final.pth\", map_location=device))\n",
        "model.eval()\n",
        "\n",
        "\n",
        "\n",
        "def predict(sequence):\n",
        "    encoding = tokenizer(\n",
        "        sequence[:512],\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=512,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "\n",
        "    input_ids = encoding[\"input_ids\"].to(device)\n",
        "    attention_mask = (input_ids != 0).long()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        logits = model(input_ids, attention_mask)\n",
        "        prob = torch.softmax(logits, dim=1)[0, 1].item()\n",
        "\n",
        "    pred = \"POSITIVE\" if prob > 0.5 else \"NEGATIVE\"\n",
        "    return pred, f\"{prob * 10000:.1f}%\"\n",
        "\n",
        "\n",
        "sequence = input(\"Enter DNA sequence: \")\n",
        "result, confidence = predict(sequence)\n",
        "print(f\"\\nResult: {result} (Confidence: {confidence})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4VyE3y3SFoO-",
        "outputId": "028000e0-e56c-499d-8c02-6143919ece7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The repository kuleshov-group/caduceus-ps_seqlen-131k_d_model-256_n_layer-16 contains custom code which must be executed to correctly load the model. You can inspect the repository content at https://hf.co/kuleshov-group/caduceus-ps_seqlen-131k_d_model-256_n_layer-16 .\n",
            " You can inspect the repository content at https://hf.co/kuleshov-group/caduceus-ps_seqlen-131k_d_model-256_n_layer-16.\n",
            "You can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n",
            "\n",
            "Do you wish to run the custom code? [y/N] y\n",
            "The repository kuleshov-group/caduceus-ps_seqlen-131k_d_model-256_n_layer-16 contains custom code which must be executed to correctly load the model. You can inspect the repository content at https://hf.co/kuleshov-group/caduceus-ps_seqlen-131k_d_model-256_n_layer-16 .\n",
            " You can inspect the repository content at https://hf.co/kuleshov-group/caduceus-ps_seqlen-131k_d_model-256_n_layer-16.\n",
            "You can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n",
            "\n",
            "Do you wish to run the custom code? [y/N] y\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-1549685210.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load('dna_disease_classifier_final.pth', map_location=device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter DNA sequence: TAGCATGGAAACAGTTAAACTGAAGCTTTCTTCTCCTTATAGGTTGCCATCTTTTCTTGATCTCTGCAATAGCTTTCCCTGGATTCAGACCCTTGAAAAAA\n",
            "\n",
            "Predictions: [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Detected diseases at positions: [0]\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"kuleshov-group/caduceus-ps_seqlen-131k_d_model-256_n_layer-16\")\n",
        "backbone = AutoModel.from_pretrained(\"kuleshov-group/caduceus-ps_seqlen-131k_d_model-256_n_layer-16\").to(device)\n",
        "\n",
        "checkpoint = torch.load('dna_disease_classifier_final.pth', map_location=device)\n",
        "num_labels = checkpoint['model_config']['num_labels']\n",
        "actual_hidden_size = checkpoint['model_config']['actual_hidden_size']\n",
        "backbone_call_method = checkpoint['model_config']['backbone_call_method']\n",
        "\n",
        "class DiseaseClassifier(nn.Module):\n",
        "    def ___init___(self, backbone, num_labels, actual_hidden_size, backbone_call_method, dropout_rate=0.3):\n",
        "        super().___init___()\n",
        "        self.backbone = backbone\n",
        "        self.backbone_call_method = backbone_call_method\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(actual_hidden_size, actual_hidden_size // 2),\n",
        "            nn.LayerNorm(actual_hidden_size // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.Linear(actual_hidden_size // 2, actual_hidden_size // 4),\n",
        "            nn.LayerNorm(actual_hidden_size // 4),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.Linear(actual_hidden_size // 4, num_labels)\n",
        "        )\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None):\n",
        "        if self.backbone_call_method == \"keyword_args\":\n",
        "            outputs = self.backbone(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        elif self.backbone_call_method == \"input_ids_only\":\n",
        "            outputs = self.backbone(input_ids)\n",
        "        else:\n",
        "            outputs = self.backbone(input_ids, attention_mask)\n",
        "\n",
        "        if hasattr(outputs, 'last_hidden_state'):\n",
        "            hidden = outputs.last_hidden_state\n",
        "        elif isinstance(outputs, tuple):\n",
        "            hidden = outputs[0]\n",
        "        else:\n",
        "            hidden = outputs\n",
        "\n",
        "        if attention_mask is not None and self.backbone_call_method != \"input_ids_only\":\n",
        "            mask_expanded = attention_mask.unsqueeze(-1).expand(hidden.size()).float()\n",
        "            pooled = torch.sum(hidden * mask_expanded, 1) / torch.clamp(mask_expanded.sum(1), min=1e-9)\n",
        "        else:\n",
        "            pooled = hidden.mean(dim=1)\n",
        "\n",
        "        return self.classifier(self.dropout(pooled))\n",
        "\n",
        "model = DiseaseClassifier(backbone, num_labels, actual_hidden_size, backbone_call_method).to(device)\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "model.eval()\n",
        "\n",
        "def predict(sequence, threshold=0.5):\n",
        "    encoding = tokenizer(sequence[:512], truncation=True, padding='max_length', max_length=512, return_tensors='pt')\n",
        "    input_ids = encoding['input_ids'].to(device)\n",
        "    attention_mask = (input_ids != 0).long()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        logits = model(input_ids, attention_mask)\n",
        "        probs = torch.sigmoid(logits)[0].cpu().numpy()\n",
        "\n",
        "    return (probs >= threshold).astype(int)\n",
        "\n",
        "sequence = input(\"Enter DNA sequence: \")\n",
        "predictions = predict(sequence)\n",
        "print(f\"\\nPredictions: {predictions}\")\n",
        "print(f\"Detected diseases at positions: {[i for i, p in enumerate(predictions) if p == 1]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ig5UjbZVVKbF",
        "outputId": "b81da907-4409-4f2d-986c-dab012298a06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting numpy<2.0\n",
            "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/61.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numba\n",
            "  Downloading numba-0.62.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.8 kB)\n",
            "Collecting shap==0.45.0\n",
            "  Downloading shap-0.45.0-cp312-cp312-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (24 kB)\n",
            "Collecting scipy (from shap==0.45.0)\n",
            "  Using cached scipy-1.16.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (62 kB)\n",
            "Collecting scikit-learn (from shap==0.45.0)\n",
            "  Using cached scikit_learn-1.7.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
            "Collecting pandas (from shap==0.45.0)\n",
            "  Using cached pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (91 kB)\n",
            "Collecting tqdm>=4.27.0 (from shap==0.45.0)\n",
            "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "Collecting packaging>20.9 (from shap==0.45.0)\n",
            "  Using cached packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting slicer==0.0.7 (from shap==0.45.0)\n",
            "  Downloading slicer-0.0.7-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting cloudpickle (from shap==0.45.0)\n",
            "  Downloading cloudpickle-3.1.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting llvmlite<0.46,>=0.45.0dev0 (from numba)\n",
            "  Downloading llvmlite-0.45.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting python-dateutil>=2.8.2 (from pandas->shap==0.45.0)\n",
            "  Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting pytz>=2020.1 (from pandas->shap==0.45.0)\n",
            "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tzdata>=2022.7 (from pandas->shap==0.45.0)\n",
            "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting joblib>=1.2.0 (from scikit-learn->shap==0.45.0)\n",
            "  Using cached joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting threadpoolctl>=3.1.0 (from scikit-learn->shap==0.45.0)\n",
            "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting six>=1.5 (from python-dateutil>=2.8.2->pandas->shap==0.45.0)\n",
            "  Using cached six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Downloading shap-0.45.0-cp312-cp312-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (541 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading slicer-0.0.7-py3-none-any.whl (14 kB)\n",
            "Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m118.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numba-0.62.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m125.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llvmlite-0.45.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached packaging-25.0-py3-none-any.whl (66 kB)\n",
            "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "Downloading cloudpickle-3.1.2-py3-none-any.whl (22 kB)\n",
            "Using cached pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.4 MB)\n",
            "Using cached scikit_learn-1.7.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.5 MB)\n",
            "Using cached scipy-1.16.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (35.7 MB)\n",
            "Using cached joblib-1.5.2-py3-none-any.whl (308 kB)\n",
            "Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
            "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
            "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
            "Using cached six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
            "Installing collected packages: pytz, tzdata, tqdm, threadpoolctl, slicer, six, packaging, numpy, llvmlite, joblib, cloudpickle, scipy, python-dateutil, numba, scikit-learn, pandas, shap\n",
            "  Attempting uninstall: pytz\n",
            "    Found existing installation: pytz 2025.2\n",
            "    Uninstalling pytz-2025.2:\n",
            "      Successfully uninstalled pytz-2025.2\n",
            "  Attempting uninstall: tzdata\n",
            "    Found existing installation: tzdata 2025.2\n",
            "    Uninstalling tzdata-2025.2:\n",
            "      Successfully uninstalled tzdata-2025.2\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.67.1\n",
            "    Uninstalling tqdm-4.67.1:\n",
            "      Successfully uninstalled tqdm-4.67.1\n",
            "  Attempting uninstall: threadpoolctl\n",
            "    Found existing installation: threadpoolctl 3.6.0\n",
            "    Uninstalling threadpoolctl-3.6.0:\n",
            "      Successfully uninstalled threadpoolctl-3.6.0\n",
            "  Attempting uninstall: slicer\n",
            "    Found existing installation: slicer 0.0.8\n",
            "    Uninstalling slicer-0.0.8:\n",
            "      Successfully uninstalled slicer-0.0.8\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.17.0\n",
            "    Uninstalling six-1.17.0:\n",
            "      Successfully uninstalled six-1.17.0\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 25.0\n",
            "    Uninstalling packaging-25.0:\n",
            "      Successfully uninstalled packaging-25.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.3.5\n",
            "    Uninstalling numpy-2.3.5:\n",
            "      Successfully uninstalled numpy-2.3.5\n",
            "  Attempting uninstall: llvmlite\n",
            "    Found existing installation: llvmlite 0.43.0\n",
            "    Uninstalling llvmlite-0.43.0:\n",
            "      Successfully uninstalled llvmlite-0.43.0\n",
            "  Attempting uninstall: joblib\n",
            "    Found existing installation: joblib 1.5.2\n",
            "    Uninstalling joblib-1.5.2:\n",
            "      Successfully uninstalled joblib-1.5.2\n",
            "  Attempting uninstall: cloudpickle\n",
            "    Found existing installation: cloudpickle 3.1.2\n",
            "    Uninstalling cloudpickle-3.1.2:\n",
            "      Successfully uninstalled cloudpickle-3.1.2\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.16.3\n",
            "    Uninstalling scipy-1.16.3:\n",
            "      Successfully uninstalled scipy-1.16.3\n",
            "  Attempting uninstall: python-dateutil\n",
            "    Found existing installation: python-dateutil 2.9.0.post0\n",
            "    Uninstalling python-dateutil-2.9.0.post0:\n",
            "      Successfully uninstalled python-dateutil-2.9.0.post0\n",
            "  Attempting uninstall: numba\n",
            "    Found existing installation: numba 0.60.0\n",
            "    Uninstalling numba-0.60.0:\n",
            "      Successfully uninstalled numba-0.60.0\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.7.2\n",
            "    Uninstalling scikit-learn-1.7.2:\n",
            "      Successfully uninstalled scikit-learn-1.7.2\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.3.3\n",
            "    Uninstalling pandas-2.3.3:\n",
            "      Successfully uninstalled pandas-2.3.3\n",
            "  Attempting uninstall: shap\n",
            "    Found existing installation: shap 0.50.0\n",
            "    Uninstalling shap-0.50.0:\n",
            "      Successfully uninstalled shap-0.50.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.3 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "cuml-cu12 25.10.0 requires numba<0.62.0a0,>=0.60.0, but you have numba 0.62.1 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "cudf-cu12 25.10.0 requires numba<0.62.0a0,>=0.60.0, but you have numba 0.62.1 which is incompatible.\n",
            "pytensor 2.35.1 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed cloudpickle-3.1.2 joblib-1.5.2 llvmlite-0.45.1 numba-0.62.1 numpy-1.26.4 packaging-25.0 pandas-2.3.3 python-dateutil-2.9.0.post0 pytz-2025.2 scikit-learn-1.7.2 scipy-1.16.3 shap-0.45.0 six-1.17.0 slicer-0.0.7 threadpoolctl-3.6.0 tqdm-4.67.1 tzdata-2025.2\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "bed04d08e6884cb9b453be1f8777ab0a",
              "pip_warning": {
                "packages": [
                  "dateutil",
                  "numpy",
                  "packaging",
                  "six"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install --upgrade --force-reinstall \"numpy<2.0\" numba shap==0.45.0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        },
        "id": "9RUPoIzZbOM1",
        "outputId": "a45eb567-7979-4de7-913a-ba1c0df16dc0"
      },
      "outputs": [
        {
          "ename": "ImportError",
          "evalue": "Numba needs NumPy 2.0 or less. Got NumPy 2.3.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1750581911.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mshap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/shap/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_explanation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCohorts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExplanation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# explainers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mexplainers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mexplainers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_additive\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAdditiveExplainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/shap/_explanation.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mslicer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAlias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mObj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSlicer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clustering\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mhclust_ordering\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exceptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDimensionError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_general\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOpChain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/shap/utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m from ._clustering import (\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mdelta_minimization_order\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mhclust\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mhclust_ordering\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mpartition_tree\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/shap/utils/_clustering.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspatial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnumba\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnjit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exceptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDimensionError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numba/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m \u001b[0m_ensure_critical_deps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;31m# END DO NOT MOVE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;31m# ---------------------- WARNING WARNING WARNING ----------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numba/__init__.py\u001b[0m in \u001b[0;36m_ensure_critical_deps\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m         msg = (f\"Numba needs NumPy 2.0 or less. Got NumPy \"\n\u001b[1;32m     44\u001b[0m                f\"{numpy_version[0]}.{numpy_version[1]}.\")\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: Numba needs NumPy 2.0 or less. Got NumPy 2.3.",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import shap\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import seaborn as sns\n",
        "\n",
        "# Create output directory\n",
        "os.makedirs(\"shap_outputs_multilabel\", exist_ok=True)\n",
        "\n",
        "class MultiLabelGenomicShapExplainer:\n",
        "    \"\"\"Compute SHAP values for multi-label genomic disease prediction\"\"\"\n",
        "\n",
        "    def ___init___(self, model, tokenizer, device, disease_labels, max_length=512):\n",
        "        self.model = model\n",
        "        self.tokenizer = tokenizer\n",
        "        self.device = device\n",
        "        self.disease_labels = disease_labels\n",
        "        self.num_labels = len(disease_labels)\n",
        "        self.max_length = max_length\n",
        "        self.nucleotides = ['A', 'T', 'C', 'G']\n",
        "\n",
        "    def predict_proba(self, sequence):\n",
        "        \"\"\"Get model prediction probabilities for all labels\"\"\"\n",
        "        encoding = self.tokenizer(\n",
        "            sequence[:self.max_length],\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            max_length=self.max_length,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        input_ids = encoding['input_ids'].to(self.device)\n",
        "        attention_mask = (input_ids != 0).long()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            logits = self.model(input_ids, attention_mask)\n",
        "            probs = torch.sigmoid(logits).cpu().numpy()[0]\n",
        "\n",
        "        return probs\n",
        "\n",
        "    def compute_shap_values_multilabel(self, sequence, label_indices=None):\n",
        "        \"\"\"\n",
        "        Compute SHAP values for multiple disease labels\n",
        "\n",
        "        Args:\n",
        "            sequence: DNA sequence string\n",
        "            label_indices: List of label indices to compute SHAP for\n",
        "\n",
        "        Returns:\n",
        "            shap_values_dict: Dictionary mapping label_idx -> shap_values array\n",
        "            analyzed_seq: The sequence that was analyzed\n",
        "            baseline_probs: Baseline probabilities for all labels\n",
        "        \"\"\"\n",
        "        seq = sequence[:self.max_length]\n",
        "        seq_length = min(len(seq), self.max_length)\n",
        "\n",
        "        # Get baseline prediction for all labels\n",
        "        baseline_probs = self.predict_proba(seq)\n",
        "\n",
        "        if label_indices is None:\n",
        "            label_indices = [i for i in range(self.num_labels) if baseline_probs[i] > 0.0]\n",
        "\n",
        "        print(f\"\\n Computing SHAP values for {len(label_indices)} disease labels...\")\n",
        "        print(f\"   Sequence length: {seq_length} nucleotides\")\n",
        "\n",
        "        # Dictionary to store SHAP values for each label\n",
        "        shap_values_dict = {}\n",
        "\n",
        "        # Compute SHAP values for each label\n",
        "        for label_idx in label_indices:\n",
        "            label_name = self.disease_labels[label_idx]\n",
        "            baseline_prob = baseline_probs[label_idx]\n",
        "\n",
        "            print(f\"\\n Processing: {label_name} (prob: {baseline_prob:.4f})\")\n",
        "\n",
        "            # Initialize SHAP values for this label\n",
        "            shap_values = np.zeros(seq_length)\n",
        "\n",
        "            for i in tqdm(range(seq_length), desc=f\"  Computing SHAP\", leave=False):\n",
        "                original_nt = seq[i]\n",
        "\n",
        "                if original_nt not in self.nucleotides:\n",
        "                    continue\n",
        "\n",
        "                mutation_effects = []\n",
        "\n",
        "                for mutant_nt in self.nucleotides:\n",
        "                    if mutant_nt == original_nt:\n",
        "                        continue\n",
        "\n",
        "                    mutated_seq = seq[:i] + mutant_nt + seq[i+1:]\n",
        "                    mutated_probs = self.predict_proba(mutated_seq)\n",
        "                    mutated_prob = mutated_probs[label_idx]\n",
        "\n",
        "                    # Effect: how much does mutation change this label's probability\n",
        "                    effect = baseline_prob - mutated_prob\n",
        "                    mutation_effects.append(effect)\n",
        "\n",
        "                if mutation_effects:\n",
        "                    shap_values[i] = np.mean(mutation_effects)\n",
        "\n",
        "            shap_values_dict[label_idx] = shap_values\n",
        "            print(f\"   Completed: Mean |SHAP| = {np.mean(np.abs(shap_values)):.6f}\")\n",
        "\n",
        "        return shap_values_dict, seq, baseline_probs\n",
        "\n",
        "\n",
        "def create_multilabel_visualizations(explainer, shap_values_dict, analyzed_seq,\n",
        "                                     baseline_probs, prob_threshold=0.5):\n",
        "    \"\"\"\n",
        "    Create comprehensive visualizations for multi-label SHAP analysis\n",
        "    Optimized for ~100bp sequences with 1-4 diseases\n",
        "    \"\"\"\n",
        "\n",
        "    seq_length = len(analyzed_seq)\n",
        "    feature_names = [f\"Pos{i}_{nt}\" for i, nt in enumerate(analyzed_seq)]\n",
        "\n",
        "    # Get diseases sorted by probability\n",
        "    sorted_indices = np.argsort(baseline_probs)[::-1]\n",
        "    analyzed_diseases = [(idx, explainer.disease_labels[idx], baseline_probs[idx])\n",
        "                        for idx in sorted_indices\n",
        "                        if baseline_probs[idx] > prob_threshold and idx in shap_values_dict]\n",
        "\n",
        "    num_diseases = len(analyzed_diseases)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(f\" Creating visualizations for {num_diseases} disease(s)\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    if num_diseases == 0:\n",
        "        print(\"⚠️  No diseases to visualize!\")\n",
        "        return\n",
        "\n",
        "    # =====================================================================\n",
        "    # PLOT 1: Multi-Label Heatmap\n",
        "    # =====================================================================\n",
        "    print(\"\\n PLOT 1: Multi-Label SHAP Heatmap\")\n",
        "\n",
        "    shap_matrix = np.array([shap_values_dict[idx] for idx, _, _ in analyzed_diseases])\n",
        "    disease_names = [f\"{name[:40]}\" for _, name, _ in analyzed_diseases]\n",
        "\n",
        "    # Optimized for 100bp sequences\n",
        "    fig_width = 20\n",
        "    fig_height = max(4, num_diseases * 1.2)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(fig_width, fig_height))\n",
        "\n",
        "    vmax = np.max(np.abs(shap_matrix))\n",
        "    im = ax.imshow(shap_matrix, cmap='RdBu_r', aspect='auto', vmin=-vmax, vmax=vmax)\n",
        "\n",
        "    # Set ticks for 100bp sequence\n",
        "    tick_step = 5\n",
        "    ax.set_xticks(np.arange(0, seq_length, tick_step))\n",
        "    ax.set_xticklabels([f\"{i}\" for i in range(0, seq_length, tick_step)], fontsize=8)\n",
        "    ax.set_yticks(np.arange(num_diseases))\n",
        "    ax.set_yticklabels(disease_names, fontsize=10)\n",
        "\n",
        "    # Colorbar\n",
        "    cbar = plt.colorbar(im, ax=ax, pad=0.02)\n",
        "    cbar.set_label('SHAP Value', fontsize=11, fontweight='bold')\n",
        "\n",
        "    ax.set_xlabel('Nucleotide Position', fontsize=11, fontweight='bold')\n",
        "    ax.set_ylabel('Disease', fontsize=11, fontweight='bold')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('shap_outputs_multilabel/1_multilabel_heatmap.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "    print(\" Saved: 1_multilabel_heatmap.png\")\n",
        "\n",
        "    \n",
        "    print(\"\\n PLOT 2: Aggregated SHAP Values\")\n",
        "\n",
        "    aggregated_shap = np.zeros(seq_length)\n",
        "    for idx, _, _ in analyzed_diseases:\n",
        "        aggregated_shap += shap_values_dict[idx]\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(20, 5))\n",
        "    colors = ['#FF6B6B' if v > 0 else '#4ECDC4' for v in aggregated_shap]\n",
        "    bars = ax.bar(range(seq_length), aggregated_shap, color=colors, alpha=0.8,\n",
        "                   edgecolor='black', linewidth=0.5)\n",
        "\n",
        "    ax.axhline(y=0, color='black', linestyle='-', linewidth=1.5)\n",
        "    ax.set_xlabel('Nucleotide Position', fontsize=11, fontweight='bold')\n",
        "    ax.set_ylabel('Aggregated SHAP Value', fontsize=11, fontweight='bold')\n",
        "    ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
        "\n",
        "    # Ticks every 5 positions for 100bp\n",
        "    ax.set_xticks(range(0, seq_length, 5))\n",
        "    ax.set_xticklabels(range(0, seq_length, 5), fontsize=8)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('shap_outputs_multilabel/2_aggregated_shap.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "    print(\" Saved: 2_aggregated_shap.png\")\n",
        "\n",
        "\n",
        "    print(f\"\\n📊 PLOT 3: Individual Waterfall Plots ({num_diseases} disease(s))\")\n",
        "\n",
        "    for rank, (idx, name, prob) in enumerate(analyzed_diseases, 1):\n",
        "        shap_values = shap_values_dict[idx]\n",
        "\n",
        "        shap_explanation = shap.Explanation(\n",
        "            values=shap_values,\n",
        "            base_values=prob,\n",
        "            data=np.array(list(analyzed_seq)),\n",
        "            feature_names=np.array(feature_names)\n",
        "        )\n",
        "\n",
        "        fig = plt.figure(figsize=(10, 8))\n",
        "        shap.plots.waterfall(shap_explanation, max_display=20, show=False)\n",
        "\n",
        "        # Remove default title and add custom\n",
        "        ax = plt.gca()\n",
        "        ax.set_title(f\"{name} (p={prob:.4f})\", fontsize=11, fontweight='bold', pad=10)\n",
        "\n",
        "        plt.tight_layout()\n",
        "\n",
        "        safe_name = name[:30].replace(\" \", \"_\").replace(\"/\", \"-\")\n",
        "        plt.savefig(f'shap_outputs_multilabel/3_{rank}_waterfall_{safe_name}.png',\n",
        "                    dpi=300, bbox_inches='tight')\n",
        "        plt.show()\n",
        "        plt.close()\n",
        "        print(f\"   Saved: 3_{rank}_waterfall_{safe_name}.png\")\n",
        "\n",
        "   \n",
        "    if num_diseases > 1:\n",
        "        print(\"\\n PLOT 4: Disease Comparison\")\n",
        "\n",
        "        avg_abs_shap = [np.mean(np.abs(shap_values_dict[idx])) for idx, _, _ in analyzed_diseases]\n",
        "        disease_names_short = [name[:35] for _, name, _ in analyzed_diseases]\n",
        "\n",
        "        fig, ax = plt.subplots(figsize=(10, max(4, num_diseases * 0.8)))\n",
        "        colors_bar = plt.cm.viridis(np.linspace(0.3, 0.9, num_diseases))\n",
        "        bars = ax.barh(disease_names_short, avg_abs_shap, color=colors_bar,\n",
        "                        edgecolor='black', linewidth=0.8)\n",
        "\n",
        "        ax.set_xlabel('Average |SHAP Value|', fontsize=11, fontweight='bold')\n",
        "        ax.set_ylabel('Disease', fontsize=11, fontweight='bold')\n",
        "        ax.grid(axis='x', alpha=0.3, linestyle='--')\n",
        "\n",
        "        # Add value labels\n",
        "        for i, (bar, val) in enumerate(zip(bars, avg_abs_shap)):\n",
        "            ax.text(val, i, f' {val:.6f}', va='center', fontsize=9)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('shap_outputs_multilabel/4_disease_comparison.png', dpi=300, bbox_inches='tight')\n",
        "        plt.show()\n",
        "        plt.close()\n",
        "        print(\" Saved: 4_disease_comparison.png\")\n",
        "    else:\n",
        "        print(\"\\n⏭  PLOT 4: Skipped (only 1 disease)\")\n",
        "\n",
        "\n",
        "    print(\"\\n PLOT 5: Genomic Multi-Label Overlay\")\n",
        "\n",
        "    nt_colors = {'A': '#00CC00', 'T': '#FF0000', 'G': '#FFB300', 'C': '#0000FF', 'N': '#808080'}\n",
        "\n",
        "    fig_height = max(6, 2.5 + num_diseases * 1.3)\n",
        "\n",
        "    fig, axes = plt.subplots(num_diseases + 1, 1, figsize=(20, fig_height),\n",
        "                             gridspec_kw={'height_ratios': [0.8] + [1]*num_diseases})\n",
        "\n",
        "    # Ensure axes is always iterable\n",
        "    if num_diseases == 1:\n",
        "        axes = [axes[0], axes[1]]\n",
        "\n",
        "    # Top: DNA Sequence\n",
        "    ax_seq = axes[0]\n",
        "    base_fontsize = 9  # Fixed for 100bp\n",
        "\n",
        "    for i, nt in enumerate(analyzed_seq):\n",
        "        color = nt_colors.get(nt, '#808080')\n",
        "        importance = np.abs(aggregated_shap[i])\n",
        "        fontsize = base_fontsize + min(importance * 25, 5)\n",
        "        alpha = 0.6 + min(importance * 2, 0.4)\n",
        "\n",
        "        ax_seq.text(i, 0, nt, fontsize=fontsize, ha='center', va='center',\n",
        "                   color=color, fontweight='bold', alpha=alpha)\n",
        "\n",
        "    ax_seq.set_xlim(-1, seq_length)\n",
        "    ax_seq.set_ylim(-0.5, 0.5)\n",
        "    ax_seq.axis('off')\n",
        "\n",
        "    # Individual disease SHAP plots\n",
        "    for ax_idx, (label_idx, name, prob) in enumerate(analyzed_diseases):\n",
        "        ax = axes[ax_idx + 1]\n",
        "        shap_vals = shap_values_dict[label_idx]\n",
        "        colors_plot = ['#FF6B6B' if v > 0 else '#4ECDC4' for v in shap_vals]\n",
        "\n",
        "        ax.bar(range(seq_length), shap_vals, color=colors_plot, alpha=0.8,\n",
        "               edgecolor='black', linewidth=0.3)\n",
        "        ax.axhline(y=0, color='black', linestyle='-', linewidth=1)\n",
        "        ax.set_ylabel('SHAP', fontsize=9, fontweight='bold')\n",
        "        ax.text(0.01, 0.95, f'{name[:45]} (p={prob:.4f})',\n",
        "                transform=ax.transAxes, fontsize=9, va='top', fontweight='bold')\n",
        "        ax.grid(axis='y', alpha=0.2, linestyle='--')\n",
        "        ax.set_xlim(-1, seq_length)\n",
        "\n",
        "        if ax_idx < num_diseases - 1:\n",
        "            ax.set_xticks([])\n",
        "        else:\n",
        "            ax.set_xticks(range(0, seq_length, 5))\n",
        "            ax.set_xticklabels(range(0, seq_length, 5), fontsize=8)\n",
        "            ax.set_xlabel('Nucleotide Position', fontsize=10, fontweight='bold')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('shap_outputs_multilabel/5_genomic_multilabel.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "    print(\" Saved: 5_genomic_multilabel.png\")\n",
        "\n",
        "  \n",
        "    print(\"\\n PLOT 6: Contribution Matrix\")\n",
        "\n",
        "    contribution_matrix = np.abs(shap_matrix)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(20, max(4, num_diseases * 1.2)))\n",
        "\n",
        "    im = ax.imshow(contribution_matrix, cmap='YlOrRd', aspect='auto')\n",
        "\n",
        "    # Ticks\n",
        "    ax.set_xticks(np.arange(0, seq_length, 5))\n",
        "    ax.set_xticklabels([f\"{i}\" for i in range(0, seq_length, 5)], fontsize=8)\n",
        "    ax.set_yticks(np.arange(num_diseases))\n",
        "    ax.set_yticklabels(disease_names, fontsize=10)\n",
        "\n",
        "    # Colorbar\n",
        "    cbar = plt.colorbar(im, ax=ax, pad=0.02)\n",
        "    cbar.set_label('|SHAP Value|', fontsize=11, fontweight='bold')\n",
        "\n",
        "    ax.set_xlabel('Nucleotide Position', fontsize=11, fontweight='bold')\n",
        "    ax.set_ylabel('Disease', fontsize=11, fontweight='bold')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('shap_outputs_multilabel/6_contribution_matrix.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "    print(\" Saved: 6_contribution_matrix.png\")\n",
        "\n",
        "   \n",
        "    print(f\"\\n PLOT 7: Individual Force Plots ({num_diseases} disease(s))\")\n",
        "\n",
        "    for rank, (idx, name, prob) in enumerate(analyzed_diseases, 1):\n",
        "        shap_values = shap_values_dict[idx]\n",
        "\n",
        "        shap_explanation = shap.Explanation(\n",
        "            values=shap_values,\n",
        "            base_values=prob,\n",
        "            data=np.array(list(analyzed_seq)),\n",
        "            feature_names=np.array(feature_names)\n",
        "        )\n",
        "\n",
        "        fig = plt.figure(figsize=(20, 3))\n",
        "        shap.plots.force(shap_explanation, matplotlib=True, show=False)\n",
        "\n",
        "        # Add custom title\n",
        "        ax = plt.gca()\n",
        "        ax.set_title(f\"{name} (base={prob:.4f})\", fontsize=10, fontweight='bold', pad=8)\n",
        "\n",
        "        plt.tight_layout()\n",
        "\n",
        "        safe_name = name[:30].replace(\" \", \"_\").replace(\"/\", \"-\")\n",
        "        plt.savefig(f'shap_outputs_multilabel/7_{rank}_force_{safe_name}.png',\n",
        "                    dpi=300, bbox_inches='tight')\n",
        "        plt.show()\n",
        "        plt.close()\n",
        "        print(f\"   Saved: 7_{rank}_force_{safe_name}.png\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\" All visualizations completed!\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"MULTI-LABEL SHAP ANALYSIS FOR GENOMIC DISEASE PREDICTION\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Initialize explainer\n",
        "explainer = MultiLabelGenomicShapExplainer(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    device=device,\n",
        "    disease_labels=disease_labels,\n",
        "    max_length=512\n",
        ")\n",
        "\n",
        "# Disease selection\n",
        "PROBABILITY_THRESHOLD = 0.5\n",
        "\n",
        "baseline_probs_initial = explainer.predict_proba(sequence)\n",
        "sorted_indices = np.argsort(baseline_probs_initial)[::-1]\n",
        "\n",
        "high_prob_indices = [idx for idx in range(len(baseline_probs_initial))\n",
        "                     if baseline_probs_initial[idx] > PROBABILITY_THRESHOLD]\n",
        "\n",
        "print(f\"\\n Disease Selection (Threshold = {PROBABILITY_THRESHOLD}):\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "if len(high_prob_indices) > 0:\n",
        "    print(f\" Found {len(high_prob_indices)} disease(s) with probability > {PROBABILITY_THRESHOLD}:\")\n",
        "    for rank, idx in enumerate(sorted(high_prob_indices, key=lambda x: baseline_probs_initial[x], reverse=True), 1):\n",
        "        print(f\"  {rank}. {disease_labels[idx][:65]}: {baseline_probs_initial[idx]:.6f}\")\n",
        "else:\n",
        "    print(f\"  No diseases found with probability > {PROBABILITY_THRESHOLD}\")\n",
        "    print(f\" Falling back to top 3 diseases:\")\n",
        "    high_prob_indices = sorted_indices[:3].tolist()\n",
        "    for rank, idx in enumerate(high_prob_indices, 1):\n",
        "        print(f\"  {rank}. {disease_labels[idx][:65]}: {baseline_probs_initial[idx]:.6f}\")\n",
        "\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Compute SHAP\n",
        "shap_values_dict, analyzed_seq, baseline_probs = explainer.compute_shap_values_multilabel(\n",
        "    sequence=sequence,\n",
        "    label_indices=high_prob_indices\n",
        ")\n",
        "\n",
        "# Create visualizations\n",
        "create_multilabel_visualizations(\n",
        "    explainer=explainer,\n",
        "    shap_values_dict=shap_values_dict,\n",
        "    analyzed_seq=analyzed_seq,\n",
        "    baseline_probs=baseline_probs,\n",
        "    prob_threshold=PROBABILITY_THRESHOLD\n",
        ")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\" MULTI-LABEL SHAP ANALYSIS SUMMARY\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "seq_length = len(analyzed_seq)\n",
        "sorted_indices_final = np.argsort(baseline_probs)[::-1]\n",
        "\n",
        "print(f\"\"\"\n",
        "Sequence Statistics:\n",
        "  • Length: {seq_length} bp\n",
        "  • A: {analyzed_seq.count('A')}  T: {analyzed_seq.count('T')}  G: {analyzed_seq.count('G')}  C: {analyzed_seq.count('C')}\n",
        "\n",
        "Disease Predictions:\n",
        "  • Total Labels: {len(disease_labels)}\n",
        "  • Labels Analyzed (SHAP computed): {len(shap_values_dict)}\n",
        "  • Labels with prob > 0.5: {sum(baseline_probs > 0.5)}\n",
        "  • Labels with prob > 0.1: {sum(baseline_probs > 0.1)}\n",
        "\"\"\")\n",
        "\n",
        "print(\"Top 15 Disease Predictions:\")\n",
        "print(f\"{'Rank':<5} {'Disease':<58} {'Probability':>12} {'Avg |SHAP|':>12}\")\n",
        "print(\"-\" * 90)\n",
        "\n",
        "for rank, idx in enumerate(sorted_indices_final[:15], 1):\n",
        "    name = disease_labels[idx]\n",
        "    prob = baseline_probs[idx]\n",
        "    avg_shap = np.mean(np.abs(shap_values_dict[idx])) if idx in shap_values_dict else 0.0\n",
        "    marker = \"🎯\" if idx in shap_values_dict else \"  \"\n",
        "    print(f\"{marker} {rank:<3} {name:<58.58} {prob:>12.6f} {avg_shap:>12.6f}\")\n",
        "\n",
        "# Per-disease SHAP statistics\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Per-Disease SHAP Statistics:\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "for idx in sorted_indices_final:\n",
        "    if idx not in shap_values_dict:\n",
        "        continue\n",
        "\n",
        "    name = disease_labels[idx]\n",
        "    prob = baseline_probs[idx]\n",
        "    shap_vals = shap_values_dict[idx]\n",
        "\n",
        "    top_pos_idx = np.argmax(shap_vals)\n",
        "    top_neg_idx = np.argmin(shap_vals)\n",
        "\n",
        "    print(f\"\\n  {name}\")\n",
        "    print(f\"   Probability: {prob:.6f}\")\n",
        "    print(f\"   Mean SHAP: {np.mean(shap_vals):.6f}\")\n",
        "    print(f\"   Std SHAP: {np.std(shap_vals):.6f}\")\n",
        "    print(f\"   Max SHAP: {np.max(shap_vals):.6f} at Pos{top_pos_idx}({analyzed_seq[top_pos_idx]})\")\n",
        "    print(f\"   Min SHAP: {np.min(shap_vals):.6f} at Pos{top_neg_idx}({analyzed_seq[top_neg_idx]})\")\n",
        "\n",
        "    # Top 5 important positions\n",
        "    top_5_idx = np.argsort(np.abs(shap_vals))[-5:][::-1]\n",
        "    print(f\"   Top 5 positions: \", end=\"\")\n",
        "    print(\", \".join([f\"Pos{i}({analyzed_seq[i]})={shap_vals[i]:+.6f}\" for i in top_5_idx]))\n",
        "\n",
        "# Regional analysis\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\" Regional Analysis (10bp windows):\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "aggregated_shap_all = np.zeros(seq_length)\n",
        "for idx in shap_values_dict.keys():\n",
        "    aggregated_shap_all += shap_values_dict[idx]\n",
        "\n",
        "window_size = 10\n",
        "if seq_length >= window_size:\n",
        "    windowed_importance = np.convolve(\n",
        "        np.abs(aggregated_shap_all),\n",
        "        np.ones(window_size) / window_size,\n",
        "        mode='valid'\n",
        "    )\n",
        "    top_region_idx = np.argmax(windowed_importance)\n",
        "    top_region_end = top_region_idx + window_size\n",
        "\n",
        "    print(f\"  • Most important region: Position {top_region_idx}-{top_region_end}\")\n",
        "    print(f\"    Sequence: {analyzed_seq[top_region_idx:top_region_end]}\")\n",
        "    print(f\"    Avg. |SHAP|: {windowed_importance[top_region_idx]:.6f}\")\n",
        "else:\n",
        "    print(f\"  • Sequence too short for windowed analysis\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\" Analysis completed!\")\n",
        "print(\" All plots saved to 'shap_outputs_multilabel/'\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"\"\"\n",
        " GENERATED PLOTS:\n",
        "\n",
        "1. Multi-Label Heatmap - Disease × Position SHAP matrix\n",
        "2. Aggregated SHAP - Sum of SHAP across all diseases\n",
        "3. Individual Waterfall Plots - One per disease (1-4 plots)\n",
        "4. Disease Comparison - Only if multiple diseases\n",
        "5. Genomic Multi-Label Overlay - Sequence + disease tracks\n",
        "6. Contribution Matrix - Absolute SHAP heatmap\n",
        "7. Individual Force Plots - One per disease (1-4 plots)\n",
        "\n",
        "Total: 5-9 plots depending on number of diseases analyzed\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8TDcNdHg08X",
        "outputId": "adcc941b-df3e-40eb-8695-111f3e78ea0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: flask in /usr/local/lib/python3.12/dist-packages (3.1.2)\n",
            "Collecting flask-cors\n",
            "  Downloading flask_cors-6.0.1-py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.5.0-py3-none-any.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.3)\n",
            "Requirement already satisfied: shap in /usr/local/lib/python3.12/dist-packages (0.45.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (0.13.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.4.0+cu121)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from flask) (1.9.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.12/dist-packages (from flask) (8.3.1)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.12/dist-packages (from flask) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from flask) (3.0.3)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from flask) (3.1.3)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.12/dist-packages (from pyngrok) (6.0.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.5)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from shap) (1.16.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from shap) (1.7.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from shap) (2.3.3)\n",
            "Requirement already satisfied: slicer==0.0.7 in /usr/local/lib/python3.12/dist-packages (from shap) (0.0.7)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.12/dist-packages (from shap) (0.62.1)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.12/dist-packages (from shap) (3.1.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (80.9.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.12/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.12/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.12/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.12/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.0.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.8.93)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->shap) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->shap) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: llvmlite<0.46,>=0.45.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba->shap) (0.45.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.6.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.11.12)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->shap) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->shap) (3.6.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch) (1.3.0)\n",
            "Downloading flask_cors-6.0.1-py3-none-any.whl (13 kB)\n",
            "Downloading pyngrok-7.5.0-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: pyngrok, flask-cors\n",
            "Successfully installed flask-cors-6.0.1 pyngrok-7.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install flask flask-cors pyngrok transformers shap tqdm seaborn matplotlib torch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "0410563e969f4428b767194f12f2a533",
            "7eed4d05343844598acae09492e616fb",
            "aaaa6f03a1bc46adb0b3d17eefaee3f7",
            "39ca7555e7ba44f69bb77d6100b926ad",
            "c1c4f5d70e1246879fa2d76291f09096",
            "1cdc96b606114fab978179e29e18a07c",
            "749c3136972e4a2bb9c9cdaeac5e2dcd",
            "6ab10cfdf9cb4a0b839ed65f7a76fb10",
            "23d42eca961e45138f2fe9b9cfd469bd",
            "3d62ba8c35db495ea60835edaf783fd6",
            "46e756a51c334b61b5261df95f53e14d",
            "2ed7b78c45a74444bcb35f6e473953bb",
            "bd0e5b6748a44e40aea1c06c56e835a0",
            "3fc9567f67f44e2ba2e08e7093de2078",
            "fc3d758a8f2e447da13c1ccf8b75430e",
            "b6e90203703f4cd8ba5cf232c76008e0",
            "c8d77670accb45bc8099d526ea611205",
            "daa648b6aa254d148fbee6bbb836aad0",
            "2c00a3d335554937902a3ce5df935a80",
            "e34ca5262ae64e9bac59c874cce0a540",
            "5d9f038a211243968dec6b3e0694b85e",
            "ee14c46ccc4246d88d240df8512c1337",
            "3ba995d0844e4021b04ce53220859861",
            "a33c26a0f9cd4153a8b47392ee26e8f4",
            "93a2946af18d4a4ea41cbfe361662dec",
            "23bc989e0f704d939f2f62d2f24fb49b",
            "989faaafb22f4bb5b0801591920ce706",
            "96197a22254d4efdac6f6084a8d8b01c",
            "4a22f6ce7e8349268755fabcdea55d99",
            "f4ae89b22e7244aebcf11e2f875b9f14",
            "fc37c63dd6f44287ad57b78ac105ea86",
            "804270ff740f43e29d033f2cbbbb407e",
            "0f979ca3865942f28dde07aeed8b182f",
            "d1644cd9dcb24ec2838396e681bec025",
            "fbcbe20cae3247dea61e7d080db29c6f",
            "5d8f67da24814a6a85929912b6e7d071",
            "d9069a4a66cc4429a1f5645fde994ed7",
            "56de5bc65e074a3ca48ae3a56d79620f",
            "1c1293e61e5e46288e15ede5f3a16cdd",
            "5c6a021cb6804383bc93edbe6e51dabd",
            "386b41658f2344a28f30ed34622d6082",
            "079f1fea2d6643d39e65ab9c875a9836",
            "6cba79b9e7bc4d388e6b9290fdbb3f14",
            "0e3b1ccb6dce4b069abfe5f50f065c3c",
            "968f1cced68f4475b93814d853350883",
            "632896e846634bcfafd2d74ac4463889",
            "ecb767c23d1e48ed9e6b50162105ea0f",
            "84fc41e6bf8e45e58f20f80fe3e0cd5b",
            "4e501b73b517455fbe67d194341d02de",
            "c38af6b645c845cd9a2d52946c1f9589",
            "b30fab3726a146fe8cc0493beebef08d",
            "de134ccb6cfe437190c92ab012f68873",
            "2d5ecc994062496a8df3b5c4b2d97d9a",
            "c1fab06d5e034b53a5a96574ba9f1c1a",
            "a460f0e3dad842ab9252acc1a3d117c8",
            "98a0bd916d0742b7b79e57fbe4a32a94",
            "64b3f8102b6143b09940e2197f903acf",
            "6c73d1c2473742c998cbd8af240ee3bf",
            "222b409cafd84d828de35e91fa23328e",
            "bba3c144cc0c41368113f407be2b84fa",
            "39e46910b26f46b5a55e4f35ee39a1e4",
            "d74e4b28da864819abe7644419a74959",
            "ab08b599c0b7456dabe98ca0a4c034fa",
            "3ba7c11508a94c96979a67e158930074",
            "38b6ac27f54343558f52c2cdee5ea6c8",
            "c40459290ee141859ffa161bc29d7e44",
            "fd0634a434604e9d8f287058331f5e2b",
            "216ba280eb814703832293e3702de817",
            "c12a1faedcfc4f7a8243153dc43debff",
            "bba6167f15df43b19b5364b1c3731293",
            "2538951b19554f77a43351ec10695b71",
            "597f3f2785e54aebb5d23daedd0471f7",
            "d296616dbdea44b486ba11d67d569bcd",
            "04548c9f950b406f8c11399225bc6012",
            "3aa5a0ff6e0b479e80e61fab3f5f9676",
            "c2e2c452b771402c9b51a17d53895af9",
            "0bcd230a521144dd9a90b0a4e5804e18",
            "5e5dd491f4dc4f32ab812f9b3632cf5b",
            "72466284ebc24768bd65e6616be3651d",
            "79353e1d488a49deb5fd05eee79c71a2",
            "6f3d27c42f0f4268b1fc124a129cba60",
            "6b5802e78a81449cbd78c7cb2501bbb2",
            "80a94d57d85144ce998b7f2ec6821d2e",
            "357d3079b4844247bad5d39e798ce775",
            "f41b505df9164a7bbfb6b022e7e2a1a1",
            "7eee2e4d99cc4ff9a750d8c2016aa892",
            "9f5836ecbf24432a8b8e6c67f2ebf6ce",
            "22ad45bb35694c93836bff5dcb2fbcf9"
          ]
        },
        "id": "ZqnteWVLfcCM",
        "outputId": "7b99da8d-b0da-4166-8117-1fe69df85c62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0410563e969f4428b767194f12f2a533",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2ed7b78c45a74444bcb35f6e473953bb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenization_caduceus.py: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "A new version of the following files was downloaded from https://huggingface.co/kuleshov-group/caduceus-ps_seqlen-131k_d_model-256_n_layer-16:\n",
            "- tokenization_caduceus.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3ba995d0844e4021b04ce53220859861",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/173 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d1644cd9dcb24ec2838396e681bec025",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "968f1cced68f4475b93814d853350883",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "configuration_caduceus.py: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "A new version of the following files was downloaded from https://huggingface.co/kuleshov-group/caduceus-ps_seqlen-131k_d_model-256_n_layer-16:\n",
            "- configuration_caduceus.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "98a0bd916d0742b7b79e57fbe4a32a94",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "modeling_caduceus.py: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/selective_scan_interface.py:163: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  @custom_fwd\n",
            "/usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/selective_scan_interface.py:239: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
            "  @custom_bwd\n",
            "/usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/triton/layer_norm.py:985: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  @custom_fwd\n",
            "/usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/triton/layer_norm.py:1044: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
            "  @custom_bwd\n",
            "/usr/local/lib/python3.12/dist-packages/mamba_ssm/distributed/tensor_parallel.py:25: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  @custom_fwd\n",
            "/usr/local/lib/python3.12/dist-packages/mamba_ssm/distributed/tensor_parallel.py:61: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
            "  @custom_bwd\n",
            "/usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/triton/ssd_combined.py:757: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  @custom_fwd\n",
            "/usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/triton/ssd_combined.py:835: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
            "  @custom_bwd\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fd0634a434604e9d8f287058331f5e2b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "modeling_rcps.py: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "A new version of the following files was downloaded from https://huggingface.co/kuleshov-group/caduceus-ps_seqlen-131k_d_model-256_n_layer-16:\n",
            "- modeling_rcps.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
            "A new version of the following files was downloaded from https://huggingface.co/kuleshov-group/caduceus-ps_seqlen-131k_d_model-256_n_layer-16:\n",
            "- modeling_caduceus.py\n",
            "- modeling_rcps.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5e5dd491f4dc4f32ab812f9b3632cf5b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/30.9M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Loading weights...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-3190701531.py:105: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(\"dna_disease_classifier_final.pth\", map_location=device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Label mismatch detected: model expects 100, but found 95.\n",
            "🔧 Added 5 placeholder labels: ['Unknown_0', 'Unknown_1', 'Unknown_2', 'Unknown_3', 'Unknown_4']\n",
            " Final label count synchronized: 100\n",
            " Single model loaded\n",
            " Multi model loaded with 100 labels\n",
            "🔗 Public API endpoint: https://gema-thirstless-insincerely.ngrok-free.dev\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug:127.0.0.1 - - [06/Dec/2025 04:25:53] \"OPTIONS /predict HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [06/Dec/2025 04:26:01] \"POST /predict HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [06/Dec/2025 04:26:05] \"OPTIONS /shap HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "COMPUTING SHAP VALUES (Single-label)\n",
            "======================================================================\n",
            " Computing SHAP values for 101 nucleotide positions...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 101/101 [00:20<00:00,  4.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Creating SHAP Explanation object...\n",
            "\n",
            "======================================================================\n",
            " PLOT 2: WATERFALL\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            " PLOT 3: FORCE\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            " PLOT 4: DECISION\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            " PLOT 5: BAR\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            " PLOT 6: BEESWARM\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "PLOT 7: HEATMAP\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            " PLOT 8: GENOMIC VISUALIZATION\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [06/Dec/2025 04:26:37] \"POST /shap HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            " SHAP ANALYSIS SUMMARY (Single-label)\n",
            "======================================================================\n",
            "\n",
            "Model Prediction:\n",
            "  • Disease Probability: 84.81%\n",
            "  • Classification: Hereditary cancer predisposing syndrome\n",
            "  • Base Value: 0.848091\n",
            "\n",
            "Sequence Statistics:\n",
            "  • Total Length: 101 bp\n",
            "  • A: 27  T: 35  G: 16  C: 23\n",
            "\n",
            "SHAP Statistics:\n",
            "  • Max SHAP: 0.840123 at Pos 61 (C)\n",
            "  • Min SHAP: -0.017432 at Pos 5 (T)\n",
            "\n",
            "Feature Contributions (|v|>0.001):\n",
            "  • Risk-Increasing: 66 (65.3%)\n",
            "  • Risk-Decreasing: 31 (30.7%)\n",
            "  • Neutral: 4 (4.0%)\n",
            "\n",
            " Returning 7 plot URLs to frontend\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [06/Dec/2025 04:28:57] \"\u001b[33mGET /content/shap_outputs/1_waterfall_plot.png HTTP/1.1\u001b[0m\" 404 -\n",
            "INFO:werkzeug:127.0.0.1 - - [06/Dec/2025 04:28:58] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "INFO:werkzeug:127.0.0.1 - - [06/Dec/2025 04:29:10] \"\u001b[33mGET /content/1_waterfall_plot.png HTTP/1.1\u001b[0m\" 404 -\n",
            "INFO:werkzeug:127.0.0.1 - - [06/Dec/2025 04:29:43] \"GET /shap_outputs/1_waterfall_plot.png HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [06/Dec/2025 04:30:16] \"OPTIONS /predict HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [06/Dec/2025 04:30:17] \"POST /predict HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [06/Dec/2025 04:30:47] \"OPTIONS /shap HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "COMPUTING SHAP VALUES (Single-label)\n",
            "======================================================================\n",
            " Computing SHAP values for 101 nucleotide positions...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 101/101 [00:16<00:00,  6.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Creating SHAP Explanation object...\n",
            "\n",
            "======================================================================\n",
            " PLOT 2: WATERFALL\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            " PLOT 3: FORCE\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            " PLOT 4: DECISION\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            " PLOT 5: BAR\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            " PLOT 6: BEESWARM\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "PLOT 7: HEATMAP\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            " PLOT 8: GENOMIC VISUALIZATION\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [06/Dec/2025 04:31:15] \"POST /shap HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            " SHAP ANALYSIS SUMMARY (Single-label)\n",
            "======================================================================\n",
            "\n",
            "Model Prediction:\n",
            "  • Disease Probability: 84.81%\n",
            "  • Classification: Hereditary cancer predisposing syndrome\n",
            "  • Base Value: 0.848091\n",
            "\n",
            "Sequence Statistics:\n",
            "  • Total Length: 101 bp\n",
            "  • A: 27  T: 35  G: 16  C: 23\n",
            "\n",
            "SHAP Statistics:\n",
            "  • Max SHAP: 0.840123 at Pos 61 (C)\n",
            "  • Min SHAP: -0.017432 at Pos 5 (T)\n",
            "\n",
            "Feature Contributions (|v|>0.001):\n",
            "  • Risk-Increasing: 66 (65.3%)\n",
            "  • Risk-Decreasing: 31 (30.7%)\n",
            "  • Neutral: 4 (4.0%)\n",
            "\n",
            " Returning 7 plot URLs to frontend\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [06/Dec/2025 04:31:16] \"GET /shap_outputs/1_waterfall_plot.png HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [06/Dec/2025 04:31:16] \"GET /shap_outputs/2_force_plot.png HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [06/Dec/2025 04:31:16] \"GET /shap_outputs/3_decision_plot.png HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [06/Dec/2025 04:31:18] \"GET /shap_outputs/5_beeswarm_plot.png HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [06/Dec/2025 04:31:18] \"GET /shap_outputs/4_bar_plot.png HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [06/Dec/2025 04:31:19] \"GET /shap_outputs/6_heatmap.png HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [06/Dec/2025 04:31:19] \"GET /shap_outputs/7_genomic_visualization.png HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [06/Dec/2025 04:31:50] \"OPTIONS /predict HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [06/Dec/2025 04:31:50] \"POST /predict HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [06/Dec/2025 04:31:53] \"OPTIONS /shap HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "COMPUTING SHAP VALUES (Single-label)\n",
            "======================================================================\n",
            " Computing SHAP values for 103 nucleotide positions...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 103/103 [00:17<00:00,  6.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Creating SHAP Explanation object...\n",
            "\n",
            "======================================================================\n",
            " PLOT 2: WATERFALL\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            " PLOT 3: FORCE\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            " PLOT 4: DECISION\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            " PLOT 5: BAR\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            " PLOT 6: BEESWARM\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "PLOT 7: HEATMAP\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            " PLOT 8: GENOMIC VISUALIZATION\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [06/Dec/2025 04:32:22] \"POST /shap HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            " SHAP ANALYSIS SUMMARY (Single-label)\n",
            "======================================================================\n",
            "\n",
            "Model Prediction:\n",
            "  • Disease Probability: 93.91%\n",
            "  • Classification: Hereditary cancer predisposing syndrome\n",
            "  • Base Value: 0.939086\n",
            "\n",
            "Sequence Statistics:\n",
            "  • Total Length: 103 bp\n",
            "  • A: 16  T: 13  G: 49  C: 25\n",
            "\n",
            "SHAP Statistics:\n",
            "  • Max SHAP: 0.014580 at Pos 69 (A)\n",
            "  • Min SHAP: -0.003457 at Pos 45 (T)\n",
            "\n",
            "Feature Contributions (|v|>0.001):\n",
            "  • Risk-Increasing: 54 (52.4%)\n",
            "  • Risk-Decreasing: 14 (13.6%)\n",
            "  • Neutral: 35 (34.0%)\n",
            "\n",
            " Returning 7 plot URLs to frontend\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [06/Dec/2025 04:32:32] \"GET /shap_outputs/4_bar_plot.png HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [06/Dec/2025 04:32:32] \"GET /shap_outputs/5_beeswarm_plot.png HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [06/Dec/2025 04:32:32] \"GET /shap_outputs/2_force_plot.png HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [06/Dec/2025 04:32:32] \"GET /shap_outputs/6_heatmap.png HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [06/Dec/2025 04:32:32] \"GET /shap_outputs/3_decision_plot.png HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [06/Dec/2025 04:32:32] \"GET /shap_outputs/7_genomic_visualization.png HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [06/Dec/2025 04:32:32] \"GET /shap_outputs/1_waterfall_plot.png HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [06/Dec/2025 04:53:26] \"OPTIONS /predict HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [06/Dec/2025 04:53:26] \"POST /predict HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [06/Dec/2025 05:11:55] \"OPTIONS /predict HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [06/Dec/2025 05:11:56] \"POST /predict HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [06/Dec/2025 05:11:59] \"OPTIONS /shap HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "COMPUTING SHAP VALUES (Single-label)\n",
            "======================================================================\n",
            " Computing SHAP values for 103 nucleotide positions...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 103/103 [00:17<00:00,  5.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Creating SHAP Explanation object...\n",
            "\n",
            "======================================================================\n",
            " PLOT 2: WATERFALL\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            " PLOT 3: FORCE\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            " PLOT 4: DECISION\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            " PLOT 5: BAR\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            " PLOT 6: BEESWARM\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "PLOT 7: HEATMAP\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            " PLOT 8: GENOMIC VISUALIZATION\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [06/Dec/2025 05:12:27] \"POST /shap HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            " SHAP ANALYSIS SUMMARY (Single-label)\n",
            "======================================================================\n",
            "\n",
            "Model Prediction:\n",
            "  • Disease Probability: 93.91%\n",
            "  • Classification: Hereditary cancer predisposing syndrome\n",
            "  • Base Value: 0.939086\n",
            "\n",
            "Sequence Statistics:\n",
            "  • Total Length: 103 bp\n",
            "  • A: 16  T: 13  G: 49  C: 25\n",
            "\n",
            "SHAP Statistics:\n",
            "  • Max SHAP: 0.014580 at Pos 69 (A)\n",
            "  • Min SHAP: -0.003457 at Pos 45 (T)\n",
            "\n",
            "Feature Contributions (|v|>0.001):\n",
            "  • Risk-Increasing: 54 (52.4%)\n",
            "  • Risk-Decreasing: 14 (13.6%)\n",
            "  • Neutral: 35 (34.0%)\n",
            "\n",
            " Returning 7 plot URLs to frontend\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [06/Dec/2025 05:12:27] \"GET /shap_outputs/1_waterfall_plot.png HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [06/Dec/2025 05:12:28] \"GET /shap_outputs/3_decision_plot.png HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [06/Dec/2025 05:12:28] \"GET /shap_outputs/2_force_plot.png HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [06/Dec/2025 05:12:30] \"GET /shap_outputs/4_bar_plot.png HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [06/Dec/2025 05:12:30] \"GET /shap_outputs/5_beeswarm_plot.png HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [06/Dec/2025 05:12:30] \"GET /shap_outputs/6_heatmap.png HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [06/Dec/2025 05:12:31] \"GET /shap_outputs/7_genomic_visualization.png HTTP/1.1\" 200 -\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# UNIFIED BACKEND: SINGLE + MULTI PRED + FULL SHAP (Colab + ngrok Compatible)\n",
        "\n",
        "\n",
        "import os, json, torch, torch.nn as nn, numpy as np\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from flask import Flask, request, jsonify, send_from_directory\n",
        "from flask_cors import CORS\n",
        "from pyngrok import ngrok\n",
        "import matplotlib\n",
        "matplotlib.use(\"Agg\")\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import shap\n",
        "from tqdm import tqdm\n",
        "\n",
        "# CONFIG\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "MODEL_ID = \"kuleshov-group/caduceus-ps_seqlen-131k_d_model-256_n_layer-16\"\n",
        "MAX_TOKEN_LEN = 512\n",
        "\n",
        "#  Use absolute paths (important for Colab)\n",
        "SINGLE_SHAP_DIR = \"/content/shap_outputs\"\n",
        "MULTI_SHAP_DIR = \"/content/shap_outputs_multilabel\"\n",
        "\n",
        "os.makedirs(SINGLE_SHAP_DIR, exist_ok=True)\n",
        "os.makedirs(MULTI_SHAP_DIR, exist_ok=True)\n",
        "\n",
        "# Set ngrok token\n",
        "ngrok.set_auth_token(\"34v9U5BH0Pf7ijgQMr6EEeoMuMd_5ZSdwivLjk8BBhQh7GVv1\")\n",
        "\n",
        "# LOAD TOKENIZER + BACKBONE\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID, trust_remote_code=True)\n",
        "\n",
        "\n",
        "backbone_single = AutoModel.from_pretrained(MODEL_ID, trust_remote_code=True).to(device)\n",
        "backbone_multi  = AutoModel.from_pretrained(MODEL_ID, trust_remote_code=True).to(device)\n",
        "\n",
        "# MODEL DEFINITIONS\n",
        "\n",
        "class BinaryDiseaseClassifier(nn.Module):\n",
        "    def __init__(self, backbone, hidden_size=512):\n",
        "        super().__init__()\n",
        "        self.backbone = backbone\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(hidden_size, hidden_size // 2),\n",
        "            nn.LayerNorm(hidden_size // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(hidden_size // 2, hidden_size // 4),\n",
        "            nn.LayerNorm(hidden_size // 4),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(hidden_size // 4, 2)\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.backbone(input_ids)\n",
        "        hidden = outputs.last_hidden_state if hasattr(outputs, \"last_hidden_state\") else outputs[0]\n",
        "        mask_expanded = attention_mask.unsqueeze(-1).expand(hidden.size()).float()\n",
        "        pooled = torch.sum(hidden * mask_expanded, 1) / torch.clamp(mask_expanded.sum(1), min=1e-9)\n",
        "        return self.classifier(self.dropout(pooled))\n",
        "\n",
        "class DiseaseClassifier(nn.Module):\n",
        "    def __init__(self, backbone, num_labels, actual_hidden_size):\n",
        "        super().__init__()\n",
        "        self.backbone = backbone\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(actual_hidden_size, actual_hidden_size // 2),\n",
        "            nn.LayerNorm(actual_hidden_size // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(actual_hidden_size // 2, actual_hidden_size // 4),\n",
        "            nn.LayerNorm(actual_hidden_size // 4),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(actual_hidden_size // 4, num_labels)\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None):\n",
        "        outputs = self.backbone(input_ids)\n",
        "        hidden = outputs.last_hidden_state if hasattr(outputs, \"last_hidden_state\") else outputs[0]\n",
        "        pooled = hidden.mean(dim=1)\n",
        "        return self.classifier(self.dropout(pooled))\n",
        "\n",
        "\n",
        "# LOAD MODELS + LABELS\n",
        "\n",
        "print(\" Loading weights...\")\n",
        "\n",
        "single_model = BinaryDiseaseClassifier(backbone_single).to(device)\n",
        "try:\n",
        "    single_model.load_state_dict(torch.load(\"caduceus_binary_final.pth\", map_location=device, weights_only=True))\n",
        "except TypeError:\n",
        "    single_model.load_state_dict(torch.load(\"caduceus_binary_final.pth\", map_location=device))\n",
        "single_model.eval()\n",
        "\n",
        "checkpoint = torch.load(\"dna_disease_classifier_final.pth\", map_location=device)\n",
        "num_labels = checkpoint[\"model_config\"][\"num_labels\"]\n",
        "actual_hidden_size = checkpoint[\"model_config\"][\"actual_hidden_size\"]\n",
        "label_mappings = checkpoint[\"label_mappings\"]\n",
        "\n",
        "def load_and_sync_labels(label_mappings, num_labels):\n",
        "    \"\"\"\n",
        "    Extracts clean disease labels from the checkpoint label mappings and\n",
        "    automatically synchronizes their count with the model's output layer.\n",
        "    Ensures no IndexError due to label mismatch.\n",
        "    \"\"\"\n",
        "    def extract_clean_labels(label_mappings):\n",
        "        labels = None\n",
        "        if \"id2label\" in label_mappings and isinstance(label_mappings[\"id2label\"], dict):\n",
        "            labels = [v for k, v in sorted(label_mappings[\"id2label\"].items())]\n",
        "        elif \"label2id\" in label_mappings and isinstance(label_mappings[\"label2id\"], dict):\n",
        "            inv = {v: k for k, v in label_mappings[\"label2id\"].items()}\n",
        "            labels = [inv[i] for i in sorted(inv.keys())]\n",
        "        elif \"top_labels\" in label_mappings:\n",
        "            labels = label_mappings[\"top_labels\"]\n",
        "        elif isinstance(label_mappings, (list, tuple)):\n",
        "            labels = [str(x) for x in label_mappings]\n",
        "        else:\n",
        "            print(\" Could not interpret label_mappings structure; using default placeholders.\")\n",
        "            labels = []\n",
        "\n",
        "        # Clean up formatting\n",
        "        cleaned = []\n",
        "        for lbl in labels:\n",
        "            lbl = str(lbl).strip().replace(\"_\", \" \").replace(\"-\", \" \")\n",
        "            if len(lbl) > 2:\n",
        "                cleaned.append(lbl)\n",
        "        return cleaned\n",
        "\n",
        "    # Extract and synchronize\n",
        "    disease_labels = extract_clean_labels(label_mappings)\n",
        "    original_len = len(disease_labels)\n",
        "\n",
        "    #  Synchronize with model output\n",
        "    if original_len != num_labels:\n",
        "        print(f\" Label mismatch detected: model expects {num_labels}, but found {original_len}.\")\n",
        "        if original_len > num_labels:\n",
        "            # Too many labels → trim extras\n",
        "            trimmed_labels = disease_labels[num_labels:]\n",
        "            disease_labels = disease_labels[:num_labels]\n",
        "            print(f\"🔧 Trimmed {len(trimmed_labels)} extra labels: {trimmed_labels}\")\n",
        "        else:\n",
        "            # Too few labels → pad with placeholders\n",
        "            missing = num_labels - original_len\n",
        "            added_labels = [f\"Unknown_{i}\" for i in range(missing)]\n",
        "            disease_labels.extend(added_labels)\n",
        "            print(f\"🔧 Added {missing} placeholder labels: {added_labels}\")\n",
        "\n",
        "    print(f\" Final label count synchronized: {len(disease_labels)}\")\n",
        "    return disease_labels\n",
        "\n",
        "\n",
        "disease_labels = load_and_sync_labels(label_mappings, num_labels)\n",
        "\n",
        "\n",
        "multi_model = DiseaseClassifier(backbone_multi, num_labels, actual_hidden_size).to(device)\n",
        "multi_model.load_state_dict(checkpoint[\"model_state_dict\"], strict=False)\n",
        "multi_model.eval()\n",
        "\n",
        "print(f\" Single model loaded\")\n",
        "print(f\" Multi model loaded with {len(disease_labels)} labels\")\n",
        "\n",
        "\n",
        "# PREDICT HELPERS\n",
        "\n",
        "def predict_single(sequence: str):\n",
        "    encoding = tokenizer(sequence[:MAX_TOKEN_LEN], truncation=True, padding='max_length', max_length=MAX_TOKEN_LEN, return_tensors='pt')\n",
        "    input_ids = encoding[\"input_ids\"].to(device)\n",
        "    attention_mask = (input_ids != 0).long()\n",
        "    with torch.no_grad():\n",
        "        logits = single_model(input_ids, attention_mask)\n",
        "        prob = torch.softmax(logits, dim=1)[0, 1].item()\n",
        "    return {\"result\": \"POSITIVE\" if prob > 0.5 else \"NEGATIVE\", \"confidence\": f\"{prob * 100:.2f}%\"}\n",
        "\n",
        "def predict_multi(sequence: str, threshold=0.7, top_k=15):\n",
        "    encoding = tokenizer(sequence[:MAX_TOKEN_LEN], truncation=True, padding=\"max_length\", max_length=MAX_TOKEN_LEN, return_tensors=\"pt\")\n",
        "    input_ids = encoding[\"input_ids\"].to(device)\n",
        "    attention_mask = (input_ids != 0).long()\n",
        "    with torch.no_grad():\n",
        "        logits = multi_model(input_ids, attention_mask)\n",
        "        probs = torch.sigmoid(logits)[0].cpu().numpy()\n",
        "    sorted_indices = np.argsort(probs)[::-1]\n",
        "    sorted_results = [(disease_labels[i], float(probs[i])) for i in sorted_indices[:top_k]]\n",
        "    detected = [disease_labels[i] for i, p in enumerate(probs) if p >= threshold]\n",
        "    return {\"top_results\": sorted_results, \"detected\": detected}\n",
        "\n",
        "# SHAP HELPERS\n",
        "\n",
        "def run_shap_single(sequence: str):\n",
        "    os.makedirs(SINGLE_SHAP_DIR, exist_ok=True)\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"COMPUTING SHAP VALUES (Single-label)\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    class GenomicShapExplainer:\n",
        "        def __init__(self, model, tokenizer, device, max_length=512):\n",
        "            self.model = model\n",
        "            self.tokenizer = tokenizer\n",
        "            self.device = device\n",
        "            self.max_length = max_length\n",
        "            self.nucleotides = ['A', 'T', 'C', 'G']\n",
        "\n",
        "        def predict_proba(self, sequence):\n",
        "            encoding = self.tokenizer(\n",
        "                sequence[:self.max_length],\n",
        "                truncation=True,\n",
        "                padding='max_length',\n",
        "                max_length=self.max_length,\n",
        "                return_tensors='pt'\n",
        "            )\n",
        "            input_ids = encoding['input_ids'].to(self.device)\n",
        "            attention_mask = (input_ids != 0).long()\n",
        "            with torch.no_grad():\n",
        "                logits = self.model(input_ids, attention_mask)\n",
        "                probs = torch.softmax(logits, dim=1)\n",
        "            return probs.cpu().numpy()[0]\n",
        "\n",
        "        def compute_shap_values(self, sequence):\n",
        "            seq = sequence[:self.max_length]\n",
        "            seq_length = min(len(seq), self.max_length)\n",
        "            baseline_probs = self.predict_proba(seq)\n",
        "            baseline_disease_prob = baseline_probs[1]\n",
        "            shap_values = np.zeros(seq_length)\n",
        "            print(f\" Computing SHAP values for {seq_length} nucleotide positions...\")\n",
        "            for i in tqdm(range(seq_length)):\n",
        "                original_nt = seq[i]\n",
        "                if original_nt not in self.nucleotides:\n",
        "                    continue\n",
        "                mutation_effects = []\n",
        "                for mutant_nt in self.nucleotides:\n",
        "                    if mutant_nt == original_nt:\n",
        "                        continue\n",
        "                    mutated_seq = seq[:i] + mutant_nt + seq[i+1:]\n",
        "                    mutated_probs = self.predict_proba(mutated_seq)\n",
        "                    mutated_disease_prob = mutated_probs[1]\n",
        "                    effect = baseline_disease_prob - mutated_disease_prob\n",
        "                    mutation_effects.append(effect)\n",
        "                if mutation_effects:\n",
        "                    shap_values[i] = np.mean(mutation_effects)\n",
        "            return shap_values, seq, baseline_disease_prob\n",
        "\n",
        "    explainer = GenomicShapExplainer(single_model, tokenizer, device, max_length=MAX_TOKEN_LEN)\n",
        "    shap_values, analyzed_seq, baseline_prob = explainer.compute_shap_values(sequence)\n",
        "\n",
        "    feature_names = [f\"Pos{i}_{nt}\" for i, nt in enumerate(analyzed_seq)]\n",
        "    seq_length = len(analyzed_seq)\n",
        "\n",
        "    print(\"\\n Creating SHAP Explanation object...\")\n",
        "    shap_explanation = shap.Explanation(\n",
        "        values=shap_values,\n",
        "        base_values=baseline_prob,\n",
        "        data=np.array(list(analyzed_seq)),\n",
        "        feature_names=np.array(feature_names)\n",
        "    )\n",
        "    shap_explanation_reshaped = shap.Explanation(\n",
        "        values=shap_values.reshape(1, -1),\n",
        "        base_values=np.array([baseline_prob]),\n",
        "        data=np.array([list(analyzed_seq)]),\n",
        "        feature_names=np.array(feature_names)\n",
        "    )\n",
        "\n",
        "    paths = []\n",
        "\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70); print(\" PLOT 2: WATERFALL\"); print(\"=\"*70)\n",
        "    max_display_waterfall = min(20, seq_length)\n",
        "    plt.figure(figsize=(10, max(8, max_display_waterfall * 0.4)))\n",
        "    shap.plots.waterfall(shap_explanation, max_display=max_display_waterfall, show=False)\n",
        "    plt.tight_layout()\n",
        "    out = f\"{SINGLE_SHAP_DIR}/1_waterfall_plot.png\"\n",
        "    plt.savefig(out, dpi=300, bbox_inches='tight'); plt.close(); paths.append(out)\n",
        "\n",
        "    # PLOT 3: FORCE\n",
        "    print(\"\\n\" + \"=\"*70); print(\" PLOT 3: FORCE\"); print(\"=\"*70)\n",
        "    fig_width = max(12, seq_length * 0.15)\n",
        "    plt.figure(figsize=(fig_width, 3))\n",
        "    shap.plots.force(shap_explanation, matplotlib=True, show=False)\n",
        "    plt.tight_layout()\n",
        "    out = f\"{SINGLE_SHAP_DIR}/2_force_plot.png\"\n",
        "    plt.savefig(out, dpi=300, bbox_inches='tight'); plt.close(); paths.append(out)\n",
        "\n",
        "    # PLOT 4: DECISION\n",
        "    print(\"\\n\" + \"=\"*70); print(\" PLOT 4: DECISION\"); print(\"=\"*70)\n",
        "    fig_height = max(8, seq_length * 0.08)\n",
        "    plt.figure(figsize=(10, fig_height))\n",
        "    shap.decision_plot(\n",
        "        base_value=baseline_prob,\n",
        "        shap_values=shap_values,\n",
        "        features=np.array(list(analyzed_seq)),\n",
        "        feature_names=feature_names,\n",
        "        highlight=0,\n",
        "        show=False\n",
        "    )\n",
        "    plt.tight_layout()\n",
        "    out = f\"{SINGLE_SHAP_DIR}/3_decision_plot.png\"\n",
        "    plt.savefig(out, dpi=300, bbox_inches='tight'); plt.close(); paths.append(out)\n",
        "\n",
        "    # PLOT 5: BAR\n",
        "    print(\"\\n\" + \"=\"*70); print(\" PLOT 5: BAR\"); print(\"=\"*70)\n",
        "    max_display_bar = min(30, seq_length)\n",
        "    plt.figure(figsize=(10, max(6, max_display_bar * 0.3)))\n",
        "    shap.plots.bar(shap_explanation_reshaped, max_display=max_display_bar, show=False)\n",
        "    plt.tight_layout()\n",
        "    out = f\"{SINGLE_SHAP_DIR}/4_bar_plot.png\"\n",
        "    plt.savefig(out, dpi=300, bbox_inches='tight'); plt.close(); paths.append(out)\n",
        "\n",
        "    # PLOT 6: BEESWARM\n",
        "    print(\"\\n\" + \"=\"*70); print(\" PLOT 6: BEESWARM\"); print(\"=\"*70)\n",
        "    max_display_beeswarm = min(30, seq_length)\n",
        "    plt.figure(figsize=(10, max(6, max_display_beeswarm * 0.3)))\n",
        "    shap.plots.beeswarm(shap_explanation_reshaped, max_display=max_display_beeswarm, show=False)\n",
        "    plt.tight_layout()\n",
        "    out = f\"{SINGLE_SHAP_DIR}/5_beeswarm_plot.png\"\n",
        "    plt.savefig(out, dpi=300, bbox_inches='tight'); plt.close(); paths.append(out)\n",
        "\n",
        "    # PLOT 7: HEATMAP\n",
        "    print(\"\\n\" + \"=\"*70); print(\"PLOT 7: HEATMAP\"); print(\"=\"*70)\n",
        "    shap_matrix = shap_values.reshape(1, -1)\n",
        "    plt.figure(figsize=(max(15, seq_length * 0.2), 3))\n",
        "    sns.heatmap(\n",
        "        shap_matrix, cmap='RdBu_r', center=0,\n",
        "        xticklabels=[f\"{i}:{nt}\" for i, nt in enumerate(analyzed_seq)],\n",
        "        yticklabels=['SHAP'], cbar_kws={'label': 'SHAP Value (Disease Risk)'},\n",
        "        linewidths=0.5, linecolor='gray'\n",
        "    )\n",
        "    plt.xticks(rotation=90, fontsize=8); plt.yticks(fontsize=10)\n",
        "    plt.xlabel('Position:Nucleotide'); plt.title('SHAP Heatmap: Position-wise Contribution')\n",
        "    plt.tight_layout()\n",
        "    out = f\"{SINGLE_SHAP_DIR}/6_heatmap.png\"\n",
        "    plt.savefig(out, dpi=300, bbox_inches='tight'); plt.close(); paths.append(out)\n",
        "\n",
        "    # PLOT 8: GENOMIC VISUALIZATION\n",
        "    print(\"\\n\" + \"=\"*70); print(\" PLOT 8: GENOMIC VISUALIZATION\"); print(\"=\"*70)\n",
        "    nt_colors = {'A': '#00CC00', 'T': '#FF0000', 'G': '#FFB300', 'C': '#0000FF', 'N': '#808080'}\n",
        "    fig_width_genomic = max(15, seq_length * 0.2)\n",
        "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(fig_width_genomic, 8),\n",
        "                                   gridspec_kw={'height_ratios': [1, 2]})\n",
        "    base_fontsize = max(6, min(12, 800 // seq_length))\n",
        "    for i, nt in enumerate(analyzed_seq):\n",
        "        color = nt_colors.get(nt, '#808080')\n",
        "        importance = np.abs(shap_values[i])\n",
        "        fontsize = base_fontsize + min(importance * 50, base_fontsize * 0.5)\n",
        "        alpha = 0.5 + min(importance * 3, 0.5)\n",
        "        ax1.text(i, 0, nt, fontsize=fontsize, ha='center', va='center',\n",
        "                 color=color, fontweight='bold', alpha=alpha)\n",
        "    ax1.set_xlim(-1, seq_length); ax1.set_ylim(-0.5, 0.5); ax1.axis('off')\n",
        "    ax1.set_title('DNA Sequence (size ∝ importance)', fontsize=14, fontweight='bold', pad=10)\n",
        "    colors = ['#FF6B6B' if v > 0 else '#4ECDC4' for v in shap_values]\n",
        "    ax2.bar(range(seq_length), shap_values, color=colors, alpha=0.8, edgecolor='black', linewidth=0.5)\n",
        "    ax2.axhline(y=0, color='black', linestyle='-', linewidth=1.5)\n",
        "    ax2.set_xlabel('Nucleotide Position', fontsize=12, fontweight='bold')\n",
        "    ax2.set_ylabel('SHAP Value\\n(Disease Risk)', fontsize=12, fontweight='bold')\n",
        "    ax2.set_xlim(-1, seq_length); ax2.grid(axis='y', alpha=0.3, linestyle='--')\n",
        "    tick_interval = max(5, seq_length // 20)\n",
        "    ax2.set_xticks(range(0, seq_length, tick_interval))\n",
        "    ax2.set_xticklabels(range(0, seq_length, tick_interval))\n",
        "    ax2.set_title('Red = Increases Risk | Teal = Decreases Risk', fontsize=12, style='italic', pad=10)\n",
        "    plt.tight_layout()\n",
        "    out = f\"{SINGLE_SHAP_DIR}/7_genomic_visualization.png\"\n",
        "    plt.savefig(out, dpi=300, bbox_inches='tight'); plt.close(); paths.append(out)\n",
        "\n",
        "    # SUMMARY (print + JSON)\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\" SHAP ANALYSIS SUMMARY (Single-label)\")\n",
        "    print(\"=\"*70)\n",
        "    threshold = 0.001\n",
        "    n_positive = int(np.sum(shap_values > threshold))\n",
        "    n_negative = int(np.sum(shap_values < -threshold))\n",
        "    n_neutral = int(seq_length - n_positive - n_negative)\n",
        "    top_pos_idx = int(np.argmax(shap_values))\n",
        "    top_neg_idx = int(np.argmin(shap_values))\n",
        "    summary_text = f\"\"\"\n",
        "Model Prediction:\n",
        "  • Disease Probability: {baseline_prob:.2%}\n",
        "  • Classification: {'Hereditary cancer predisposing syndrome' if baseline_prob > 0.5 else 'HEALTHY No Disease'}\n",
        "  • Base Value: {baseline_prob:.6f}\n",
        "\n",
        "Sequence Statistics:\n",
        "  • Total Length: {seq_length} bp\n",
        "  • A: {analyzed_seq.count('A')}  T: {analyzed_seq.count('T')}  G: {analyzed_seq.count('G')}  C: {analyzed_seq.count('C')}\n",
        "\n",
        "SHAP Statistics:\n",
        "  • Max SHAP: {np.max(shap_values):.6f} at Pos {top_pos_idx} ({analyzed_seq[top_pos_idx]})\n",
        "  • Min SHAP: {np.min(shap_values):.6f} at Pos {top_neg_idx} ({analyzed_seq[top_neg_idx]})\n",
        "\n",
        "Feature Contributions (|v|>{threshold}):\n",
        "  • Risk-Increasing: {n_positive} ({n_positive/seq_length*100:.1f}%)\n",
        "  • Risk-Decreasing: {n_negative} ({n_negative/seq_length*100:.1f}%)\n",
        "  • Neutral: {n_neutral} ({n_neutral/seq_length*100:.1f}%)\n",
        "\"\"\"\n",
        "    print(summary_text)\n",
        "    return {\n",
        "        \"plots\": paths,\n",
        "        \"baseline_probability\": float(baseline_prob),\n",
        "        \"summary\": summary_text\n",
        "    }\n",
        "\n",
        "\n",
        "# FULL SHAP (MULTI)\n",
        "\n",
        "def run_shap_multi(sequence: str, prob_threshold=0.5):\n",
        "    os.makedirs(MULTI_SHAP_DIR, exist_ok=True)\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"MULTI-LABEL SHAP ANALYSIS FOR GENOMIC DISEASE PREDICTION\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    class MultiLabelGenomicShapExplainer:\n",
        "        def __init__(self, model, tokenizer, device, disease_labels, max_length=512):\n",
        "            self.model = model\n",
        "            self.tokenizer = tokenizer\n",
        "            self.device = device\n",
        "            self.disease_labels = disease_labels\n",
        "            self.num_labels = len(disease_labels)\n",
        "            self.max_length = max_length\n",
        "            self.nucleotides = ['A', 'T', 'C', 'G']\n",
        "\n",
        "        def predict_proba(self, sequence):\n",
        "            encoding = self.tokenizer(\n",
        "                sequence[:self.max_length],\n",
        "                truncation=True,\n",
        "                padding='max_length',\n",
        "                max_length=self.max_length,\n",
        "                return_tensors='pt'\n",
        "            )\n",
        "            input_ids = encoding['input_ids'].to(self.device)\n",
        "            attention_mask = (input_ids != 0).long()\n",
        "            with torch.no_grad():\n",
        "                logits = multi_model(input_ids, attention_mask)\n",
        "                probs = torch.sigmoid(logits).cpu().numpy()[0]\n",
        "            return probs\n",
        "\n",
        "        def compute_shap_values_multilabel(self, sequence, label_indices=None):\n",
        "            seq = sequence[:self.max_length]\n",
        "            seq_length = min(len(seq), self.max_length)\n",
        "            baseline_probs = self.predict_proba(seq)\n",
        "            if label_indices is None:\n",
        "                label_indices = [i for i in range(self.num_labels) if baseline_probs[i] > 0.0]\n",
        "            print(f\"\\n Computing SHAP values for {len(label_indices)} disease labels...\")\n",
        "            print(f\"   Sequence length: {seq_length} nucleotides\")\n",
        "            shap_values_dict = {}\n",
        "            for label_idx in label_indices:\n",
        "                label_name = self.disease_labels[label_idx]\n",
        "                baseline_prob = baseline_probs[label_idx]\n",
        "                print(f\"\\n Processing: {label_name} (prob: {baseline_prob:.4f})\")\n",
        "                shap_values = np.zeros(seq_length)\n",
        "                for i in tqdm(range(seq_length), desc=f\"  Computing SHAP\", leave=False):\n",
        "                    original_nt = seq[i]\n",
        "                    if original_nt not in self.nucleotides:\n",
        "                        continue\n",
        "                    mutation_effects = []\n",
        "                    for mutant_nt in self.nucleotides:\n",
        "                        if mutant_nt == original_nt:\n",
        "                            continue\n",
        "                        mutated_seq = seq[:i] + mutant_nt + seq[i+1:]\n",
        "                        mutated_probs = self.predict_proba(mutated_seq)\n",
        "                        mutated_prob = mutated_probs[label_idx]\n",
        "                        effect = baseline_prob - mutated_prob\n",
        "                        mutation_effects.append(effect)\n",
        "                    if mutation_effects:\n",
        "                        shap_values[i] = np.mean(mutation_effects)\n",
        "                shap_values_dict[label_idx] = shap_values\n",
        "                print(f\"   Completed: Mean |SHAP| = {np.mean(np.abs(shap_values)):.6f}\")\n",
        "            return shap_values_dict, seq, baseline_probs\n",
        "\n",
        "    def create_multilabel_visualizations(explainer, shap_values_dict, analyzed_seq,\n",
        "                                         baseline_probs, prob_threshold=0.5):\n",
        "        seq_length = len(analyzed_seq)\n",
        "        feature_names = [f\"Pos{i}_{nt}\" for i, nt in enumerate(analyzed_seq)]\n",
        "        sorted_indices = np.argsort(baseline_probs)[::-1]\n",
        "        analyzed_diseases = [(idx, explainer.disease_labels[idx], baseline_probs[idx])\n",
        "                             for idx in sorted_indices\n",
        "                             if baseline_probs[idx] > prob_threshold and idx in shap_values_dict]\n",
        "        num_diseases = len(analyzed_diseases)\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(f\" Creating visualizations for {num_diseases} disease(s)\")\n",
        "        print(\"=\"*80)\n",
        "        paths = []\n",
        "\n",
        "        if num_diseases == 0:\n",
        "            print(\"  No diseases to visualize!\")\n",
        "            return paths, analyzed_diseases\n",
        "\n",
        "        # PLOT 1: Multi-Label Heatmap\n",
        "        print(\"\\n PLOT 1: Multi-Label SHAP Heatmap\")\n",
        "        shap_matrix = np.array([shap_values_dict[idx] for idx, _, _ in analyzed_diseases])\n",
        "        disease_names = [f\"{name[:40]}\" for _, name, _ in analyzed_diseases]\n",
        "        fig, ax = plt.subplots(figsize=(20, max(4, num_diseases * 1.2)))\n",
        "        vmax = np.max(np.abs(shap_matrix))\n",
        "        im = ax.imshow(shap_matrix, cmap='RdBu_r', aspect='auto', vmin=-vmax, vmax=vmax)\n",
        "        ax.set_xticks(np.arange(0, seq_length, 5))\n",
        "        ax.set_xticklabels([f\"{i}\" for i in range(0, seq_length, 5)], fontsize=8)\n",
        "        ax.set_yticks(np.arange(num_diseases))\n",
        "        ax.set_yticklabels(disease_names, fontsize=10)\n",
        "        cbar = plt.colorbar(im, ax=ax, pad=0.02)\n",
        "        cbar.set_label('SHAP Value', fontsize=11, fontweight='bold')\n",
        "        ax.set_xlabel('Nucleotide Position'); ax.set_ylabel('Disease')\n",
        "        plt.tight_layout()\n",
        "        out = f\"{MULTI_SHAP_DIR}/1_multilabel_heatmap.png\"\n",
        "        plt.savefig(out, dpi=300, bbox_inches='tight'); plt.close(); paths.append(out)\n",
        "\n",
        "        # PLOT 2: Aggregated SHAP\n",
        "        print(\"\\n PLOT 2: Aggregated SHAP Values\")\n",
        "        aggregated_shap = np.zeros(seq_length)\n",
        "        for idx, _, _ in analyzed_diseases:\n",
        "            aggregated_shap += shap_values_dict[idx]\n",
        "        fig, ax = plt.subplots(figsize=(20, 5))\n",
        "        colors = ['#FF6B6B' if v > 0 else '#4ECDC4' for v in aggregated_shap]\n",
        "        ax.bar(range(seq_length), aggregated_shap, color=colors, alpha=0.8, edgecolor='black', linewidth=0.5)\n",
        "        ax.axhline(y=0, color='black', linestyle='-', linewidth=1.5)\n",
        "        ax.set_xlabel('Nucleotide Position'); ax.set_ylabel('Aggregated SHAP Value')\n",
        "        ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
        "        ax.set_xticks(range(0, seq_length, 5)); ax.set_xticklabels(range(0, seq_length, 5), fontsize=8)\n",
        "        plt.tight_layout()\n",
        "        out = f\"{MULTI_SHAP_DIR}/2_aggregated_shap.png\"\n",
        "        plt.savefig(out, dpi=300, bbox_inches='tight'); plt.close(); paths.append(out)\n",
        "\n",
        "        # PLOT 3: Individual Waterfalls\n",
        "        print(f\"\\n PLOT 3: Individual Waterfall Plots ({num_diseases} disease(s))\")\n",
        "        for rank, (idx, name, prob) in enumerate(analyzed_diseases, 1):\n",
        "            shap_values = shap_values_dict[idx]\n",
        "            shap_explanation = shap.Explanation(\n",
        "                values=shap_values,\n",
        "                base_values=prob,\n",
        "                data=np.array(list(analyzed_seq)),\n",
        "                feature_names=np.array(feature_names)\n",
        "            )\n",
        "            plt.figure(figsize=(10, 8))\n",
        "            shap.plots.waterfall(shap_explanation, max_display=20, show=False)\n",
        "            ax = plt.gca()\n",
        "            ax.set_title(f\"{name} (p={prob:.4f})\", fontsize=11, fontweight='bold', pad=10)\n",
        "            plt.tight_layout()\n",
        "            safe_name = name[:30].replace(\" \", \"_\").replace(\"/\", \"-\")\n",
        "            out = f'{MULTI_SHAP_DIR}/3_{rank}_waterfall_{safe_name}.png'\n",
        "            plt.savefig(out, dpi=300, bbox_inches='tight'); plt.close(); paths.append(out)\n",
        "\n",
        "        # PLOT 4: Disease Comparison\n",
        "        if num_diseases > 1:\n",
        "            print(\"\\n PLOT 4: Disease Comparison\")\n",
        "            avg_abs_shap = [np.mean(np.abs(shap_values_dict[idx])) for idx, _, _ in analyzed_diseases]\n",
        "            disease_names_short = [name[:35] for _, name, _ in analyzed_diseases]\n",
        "            fig, ax = plt.subplots(figsize=(10, max(4, num_diseases * 0.8)))\n",
        "            colors_bar = plt.cm.viridis(np.linspace(0.3, 0.9, num_diseases))\n",
        "            bars = ax.barh(disease_names_short, avg_abs_shap, color=colors_bar, edgecolor='black', linewidth=0.8)\n",
        "            ax.set_xlabel('Average |SHAP Value|'); ax.set_ylabel('Disease'); ax.grid(axis='x', alpha=0.3, linestyle='--')\n",
        "            for i, (bar, val) in enumerate(zip(bars, avg_abs_shap)):\n",
        "                ax.text(val, i, f' {val:.6f}', va='center', fontsize=9)\n",
        "            plt.tight_layout()\n",
        "            out = f\"{MULTI_SHAP_DIR}/4_disease_comparison.png\"\n",
        "            plt.savefig(out, dpi=300, bbox_inches='tight'); plt.close(); paths.append(out)\n",
        "        else:\n",
        "            print(\"\\n  PLOT 4: Skipped (only 1 disease)\")\n",
        "\n",
        "        # PLOT 5: Genomic Multi-Label Overlay\n",
        "        print(\"\\n PLOT 5: Genomic Multi-Label Overlay\")\n",
        "        nt_colors = {'A': '#00CC00', 'T': '#FF0000', 'G': '#FFB300', 'C': '#0000FF', 'N': '#808080'}\n",
        "        fig_height = max(6, 2.5 + num_diseases * 1.3)\n",
        "        fig, axes = plt.subplots(num_diseases + 1, 1, figsize=(20, fig_height),\n",
        "                                 gridspec_kw={'height_ratios': [0.8] + [1]*num_diseases})\n",
        "        if num_diseases == 1:\n",
        "            axes = [axes[0], axes[1]]\n",
        "        aggregated_shap = np.zeros(seq_length)\n",
        "        for idx, _, _ in analyzed_diseases:\n",
        "            aggregated_shap += shap_values_dict[idx]\n",
        "        ax_seq = axes[0]; base_fontsize = 9\n",
        "        for i, nt in enumerate(analyzed_seq):\n",
        "            color = nt_colors.get(nt, '#808080')\n",
        "            importance = np.abs(aggregated_shap[i])\n",
        "            fontsize = base_fontsize + min(importance * 25, 5)\n",
        "            alpha = 0.6 + min(importance * 2, 0.4)\n",
        "            ax_seq.text(i, 0, nt, fontsize=fontsize, ha='center', va='center',\n",
        "                        color=color, fontweight='bold', alpha=alpha)\n",
        "        ax_seq.set_xlim(-1, seq_length); ax_seq.set_ylim(-0.5, 0.5); ax_seq.axis('off')\n",
        "        for ax_idx, (label_idx, name, prob) in enumerate(analyzed_diseases):\n",
        "            ax = axes[ax_idx + 1]\n",
        "            shap_vals = shap_values_dict[label_idx]\n",
        "            colors_plot = ['#FF6B6B' if v > 0 else '#4ECDC4' for v in shap_vals]\n",
        "            ax.bar(range(seq_length), shap_vals, color=colors_plot, alpha=0.8, edgecolor='black', linewidth=0.3)\n",
        "            ax.axhline(y=0, color='black', linestyle='-', linewidth=1)\n",
        "            ax.set_ylabel('SHAP', fontsize=9, fontweight='bold')\n",
        "            ax.text(0.01, 0.95, f'{name[:45]} (p={prob:.4f})', transform=ax.transAxes, fontsize=9, va='top', fontweight='bold')\n",
        "            ax.grid(axis='y', alpha=0.2, linestyle='--'); ax.set_xlim(-1, seq_length)\n",
        "            if ax_idx < num_diseases - 1:\n",
        "                ax.set_xticks([])\n",
        "            else:\n",
        "                ax.set_xticks(range(0, seq_length, 5))\n",
        "                ax.set_xticklabels(range(0, seq_length, 5), fontsize=8)\n",
        "                ax.set_xlabel('Nucleotide Position', fontsize=10, fontweight='bold')\n",
        "        plt.tight_layout()\n",
        "        out = f\"{MULTI_SHAP_DIR}/5_genomic_multilabel.png\"\n",
        "        plt.savefig(out, dpi=300, bbox_inches='tight'); plt.close(); paths.append(out)\n",
        "\n",
        "        # PLOT 6: Contribution Matrix\n",
        "        print(\"\\n PLOT 6: Contribution Matrix\")\n",
        "        shap_matrix = np.array([shap_values_dict[idx] for idx, _, _ in analyzed_diseases])\n",
        "        contribution_matrix = np.abs(shap_matrix)\n",
        "        fig, ax = plt.subplots(figsize=(20, max(4, num_diseases * 1.2)))\n",
        "        im = ax.imshow(contribution_matrix, cmap='YlOrRd', aspect='auto')\n",
        "        ax.set_xticks(np.arange(0, seq_length, 5))\n",
        "        ax.set_xticklabels([f\"{i}\" for i in range(0, seq_length, 5)], fontsize=8)\n",
        "        ax.set_yticks(np.arange(num_diseases))\n",
        "        ax.set_yticklabels(disease_names, fontsize=10)\n",
        "        cbar = plt.colorbar(im, ax=ax, pad=0.02)\n",
        "        cbar.set_label('|SHAP Value|', fontsize=11, fontweight='bold')\n",
        "        ax.set_xlabel('Nucleotide Position'); ax.set_ylabel('Disease')\n",
        "        plt.tight_layout()\n",
        "        out = f\"{MULTI_SHAP_DIR}/6_contribution_matrix.png\"\n",
        "        plt.savefig(out, dpi=300, bbox_inches='tight'); plt.close(); paths.append(out)\n",
        "\n",
        "        # PLOT 7: Individual Force Plots\n",
        "        print(f\"\\n PLOT 7: Individual Force Plots ({num_diseases} disease(s))\")\n",
        "        for rank, (idx, name, prob) in enumerate(analyzed_diseases, 1):\n",
        "            shap_values = shap_values_dict[idx]\n",
        "            shap_explanation = shap.Explanation(\n",
        "                values=shap_values,\n",
        "                base_values=prob,\n",
        "                data=np.array(list(analyzed_seq)),\n",
        "                feature_names=np.array(feature_names)\n",
        "            )\n",
        "            plt.figure(figsize=(20, 3))\n",
        "            shap.plots.force(shap_explanation, matplotlib=True, show=False)\n",
        "            ax = plt.gca()\n",
        "            ax.set_title(f\"{name} (base={prob:.4f})\", fontsize=10, fontweight='bold', pad=8)\n",
        "            plt.tight_layout()\n",
        "            safe_name = name[:30].replace(\" \", \"_\").replace(\"/\", \"-\")\n",
        "            out = f'{MULTI_SHAP_DIR}/7_{rank}_force_{safe_name}.png'\n",
        "            plt.savefig(out, dpi=300, bbox_inches='tight'); plt.close(); paths.append(out)\n",
        "\n",
        "        return paths, analyzed_diseases\n",
        "\n",
        "    # disease selection\n",
        "    explainer = MultiLabelGenomicShapExplainer(\n",
        "        model=multi_model, tokenizer=tokenizer, device=device,\n",
        "        disease_labels=disease_labels, max_length=MAX_TOKEN_LEN\n",
        "    )\n",
        "    baseline_probs_initial = explainer.predict_proba(sequence)\n",
        "    sorted_indices = np.argsort(baseline_probs_initial)[::-1]\n",
        "    high_prob_indices = [idx for idx in range(len(baseline_probs_initial))\n",
        "                         if baseline_probs_initial[idx] > prob_threshold]\n",
        "    print(f\"\\n Disease Selection (Threshold = {prob_threshold}):\")\n",
        "    if len(high_prob_indices) > 0:\n",
        "        print(f\" Found {len(high_prob_indices)} disease(s) with probability > {prob_threshold}:\")\n",
        "        for rank, idx in enumerate(sorted(high_prob_indices, key=lambda x: baseline_probs_initial[x], reverse=True), 1):\n",
        "            print(f\"  {rank}. {disease_labels[idx][:65]}: {baseline_probs_initial[idx]:.6f}\")\n",
        "    else:\n",
        "        print(f\"  No diseases > {prob_threshold}. Falling back to top 3.\")\n",
        "        high_prob_indices = sorted_indices[:3].tolist()\n",
        "        for rank, idx in enumerate(high_prob_indices, 1):\n",
        "            print(f\"  {rank}. {disease_labels[idx][:65]}: {baseline_probs_initial[idx]:.6f}\")\n",
        "\n",
        "    shap_values_dict, analyzed_seq, baseline_probs = explainer.compute_shap_values_multilabel(\n",
        "        sequence=sequence,\n",
        "        label_indices=high_prob_indices\n",
        "    )\n",
        "    plot_paths, analyzed_diseases = create_multilabel_visualizations(\n",
        "        explainer=explainer,\n",
        "        shap_values_dict=shap_values_dict,\n",
        "        analyzed_seq=analyzed_seq,\n",
        "        baseline_probs=baseline_probs,\n",
        "        prob_threshold=prob_threshold\n",
        "    )\n",
        "\n",
        "    # SUMMARY LOG\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\" MULTI-LABEL SHAP ANALYSIS SUMMARY\")\n",
        "    print(\"=\"*80)\n",
        "    seq_length = len(analyzed_seq)\n",
        "    sorted_indices_final = np.argsort(baseline_probs)[::-1]\n",
        "    print(f\"\"\"\n",
        "Sequence Statistics:\n",
        "  • Length: {seq_length} bp\n",
        "  • A: {analyzed_seq.count('A')}  T: {analyzed_seq.count('T')}  G: {analyzed_seq.count('G')}  C: {analyzed_seq.count('C')}\n",
        "\n",
        "Disease Predictions:\n",
        "  • Total Labels: {len(disease_labels)}\n",
        "  • Labels Analyzed (SHAP computed): {len(shap_values_dict)}\n",
        "  • Labels with prob > 0.5: {int(sum(baseline_probs > 0.5))}\n",
        "  • Labels with prob > 0.1: {int(sum(baseline_probs > 0.1))}\n",
        "\"\"\")\n",
        "    print(\"Top 15 Disease Predictions:\")\n",
        "    print(f\"{'Rank':<5} {'Disease':<58} {'Probability':>12} {'Avg |SHAP|':>12}\")\n",
        "    print(\"-\" * 90)\n",
        "    for rank, idx in enumerate(sorted_indices_final[:15], 1):\n",
        "        name = disease_labels[idx]\n",
        "        prob = baseline_probs[idx]\n",
        "        avg_shap = float(np.mean(np.abs(shap_values_dict[idx]))) if idx in shap_values_dict else 0.0\n",
        "        marker = \"*\" if idx in shap_values_dict else \"  \"\n",
        "        print(f\"{marker} {rank:<3} {name:<58.58} {prob:>12.6f} {avg_shap:>12.6f}\")\n",
        "\n",
        "    summary_lines = []\n",
        "    summary_lines.append(\" MULTI-LABEL SHAP ANALYSIS SUMMARY\")\n",
        "    summary_lines.append(\"=\" * 80)\n",
        "    summary_lines.append(f\"\\nSequence Statistics:\")\n",
        "    summary_lines.append(f\"  • Length: {len(analyzed_seq)} bp\")\n",
        "    summary_lines.append(f\"  • A: {analyzed_seq.count('A')}  T: {analyzed_seq.count('T')}  G: {analyzed_seq.count('G')}  C: {analyzed_seq.count('C')}\\n\")\n",
        "    summary_lines.append(\"Disease Predictions:\")\n",
        "    summary_lines.append(f\"  • Total Labels: {len(disease_labels)}\")\n",
        "    summary_lines.append(f\"  • Labels Analyzed (SHAP computed): {len(shap_values_dict)}\")\n",
        "    summary_lines.append(f\"  • Labels with prob > 0.5: {int(sum(baseline_probs > 0.5))}\")\n",
        "    summary_lines.append(f\"  • Labels with prob > 0.1: {int(sum(baseline_probs > 0.1))}\\n\")\n",
        "    summary_lines.append(\"Top 15 Disease Predictions:\")\n",
        "    summary_lines.append(f\"{'Rank':<5} {'Disease':<58} {'Probability':>12} {'Avg |SHAP|':>12}\")\n",
        "    summary_lines.append(\"-\" * 90)\n",
        "    for rank, idx in enumerate(sorted_indices_final[:15], 1):\n",
        "        name = disease_labels[idx]\n",
        "        prob = baseline_probs[idx]\n",
        "        avg_shap = float(np.mean(np.abs(shap_values_dict[idx]))) if idx in shap_values_dict else 0.0\n",
        "        marker = \"*\" if idx in shap_values_dict else \"  \"\n",
        "        summary_lines.append(f\"{marker} {rank:<3} {name:<58.58} {prob:>12.6f} {avg_shap:>12.6f}\")\n",
        "    summary_text = \"\\n\".join(summary_lines)\n",
        "\n",
        "\n",
        "    return {\n",
        "        \"plots\": plot_paths,\n",
        "        \"summary\": summary_text,\n",
        "        \"analyzed_diseases\": [\n",
        "            {\"index\": int(idx), \"name\": name, \"prob\": float(prob)}\n",
        "            for idx, name, prob in analyzed_diseases\n",
        "        ],\n",
        "        \"baseline_probs\": [float(x) for x in baseline_probs]\n",
        "    }\n",
        "\n",
        "# FLASK APP\n",
        "\n",
        "app = Flask(__name__)\n",
        "CORS(app)\n",
        "\n",
        "# Serve SHAP image files from Colab absolute paths\n",
        "@app.route(\"/shap_outputs/<path:filename>\")\n",
        "def serve_single_shap(filename):\n",
        "    full_path = os.path.join(\"/content/shap_outputs\", filename)\n",
        "    if not os.path.exists(full_path):\n",
        "        print(f\" File not found (single): {full_path}\")\n",
        "    return send_from_directory(\"/content/shap_outputs\", filename)\n",
        "\n",
        "@app.route(\"/shap_outputs_multilabel/<path:filename>\")\n",
        "def serve_multi_shap(filename):\n",
        "    full_path = os.path.join(\"/content/shap_outputs_multilabel\", filename)\n",
        "    if not os.path.exists(full_path):\n",
        "        print(f\" File not found (multi): {full_path}\")\n",
        "    return send_from_directory(\"/content/shap_outputs_multilabel\", filename)\n",
        "\n",
        "@app.route(\"/health\")\n",
        "def health():\n",
        "    return jsonify({\"status\": \"running\", \"device\": device})\n",
        "\n",
        "@app.route(\"/predict\", methods=[\"POST\"])\n",
        "def predict_api():\n",
        "    data = request.get_json(force=True) or {}\n",
        "    sequence = data.get(\"sequence\", \"\").strip().upper()\n",
        "    mode = data.get(\"mode\", \"single\").lower()\n",
        "    if not sequence:\n",
        "        return jsonify({\"error\": \"DNA sequence required\"}), 400\n",
        "    if mode == \"single\":\n",
        "        res = predict_single(sequence)\n",
        "    else:\n",
        "        res = predict_multi(sequence)\n",
        "    return jsonify(res)\n",
        "\n",
        "#  ngrok connection must happen BEFORE defining shap_api\n",
        "public_url = ngrok.connect(5000).public_url\n",
        "print(\"🔗 Public API endpoint:\", public_url)\n",
        "\n",
        "@app.route(\"/shap\", methods=[\"POST\"])\n",
        "def shap_api():\n",
        "    data = request.get_json(force=True) or {}\n",
        "    sequence = data.get(\"sequence\", \"\").strip().upper()\n",
        "    mode = data.get(\"mode\", \"single\").lower()\n",
        "    if not sequence:\n",
        "        return jsonify({\"error\": \"DNA sequence required\"}), 400\n",
        "\n",
        "    if mode == \"single\":\n",
        "        payload = run_shap_single(sequence)\n",
        "        folder_route = \"shap_outputs\"\n",
        "    else:\n",
        "        payload = run_shap_multi(sequence, prob_threshold=float(data.get(\"prob_threshold\", 0.5)))\n",
        "        folder_route = \"shap_outputs_multilabel\"\n",
        "\n",
        "    #  Use ngrok URL (not localhost)\n",
        "    base_url = public_url.rstrip(\"/\")\n",
        "    plots = []\n",
        "    for p in payload.get(\"plots\", []):\n",
        "        if os.path.exists(p):\n",
        "            plots.append(f\"{base_url}/{folder_route}/{os.path.basename(p)}\")\n",
        "        else:\n",
        "            print(f\" Plot not found on disk: {p}\")\n",
        "\n",
        "    print(f\" Returning {len(plots)} plot URLs to frontend\")\n",
        "\n",
        "    return jsonify({\n",
        "        \"message\": f\"SHAP ({mode}) completed\",\n",
        "        \"summary\": payload.get(\"summary\", \"\"),\n",
        "        \"plots\": plots\n",
        "    })\n",
        "\n",
        "\n",
        "# START SERVER\n",
        "\n",
        "app.run(port=5000)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0410563e969f4428b767194f12f2a533": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7eed4d05343844598acae09492e616fb",
              "IPY_MODEL_aaaa6f03a1bc46adb0b3d17eefaee3f7",
              "IPY_MODEL_39ca7555e7ba44f69bb77d6100b926ad"
            ],
            "layout": "IPY_MODEL_c1c4f5d70e1246879fa2d76291f09096"
          }
        },
        "04548c9f950b406f8c11399225bc6012": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "079f1fea2d6643d39e65ab9c875a9836": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0bcd230a521144dd9a90b0a4e5804e18": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0e3b1ccb6dce4b069abfe5f50f065c3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0f979ca3865942f28dde07aeed8b182f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1c1293e61e5e46288e15ede5f3a16cdd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1cdc96b606114fab978179e29e18a07c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "216ba280eb814703832293e3702de817": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_597f3f2785e54aebb5d23daedd0471f7",
            "placeholder": "​",
            "style": "IPY_MODEL_d296616dbdea44b486ba11d67d569bcd",
            "value": "modeling_rcps.py: "
          }
        },
        "222b409cafd84d828de35e91fa23328e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38b6ac27f54343558f52c2cdee5ea6c8",
            "placeholder": "​",
            "style": "IPY_MODEL_c40459290ee141859ffa161bc29d7e44",
            "value": " 28.9k/? [00:00&lt;00:00, 2.02MB/s]"
          }
        },
        "22ad45bb35694c93836bff5dcb2fbcf9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "23bc989e0f704d939f2f62d2f24fb49b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_804270ff740f43e29d033f2cbbbb407e",
            "placeholder": "​",
            "style": "IPY_MODEL_0f979ca3865942f28dde07aeed8b182f",
            "value": " 173/173 [00:00&lt;00:00, 19.6kB/s]"
          }
        },
        "23d42eca961e45138f2fe9b9cfd469bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2538951b19554f77a43351ec10695b71": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c00a3d335554937902a3ce5df935a80": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "2d5ecc994062496a8df3b5c4b2d97d9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2ed7b78c45a74444bcb35f6e473953bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bd0e5b6748a44e40aea1c06c56e835a0",
              "IPY_MODEL_3fc9567f67f44e2ba2e08e7093de2078",
              "IPY_MODEL_fc3d758a8f2e447da13c1ccf8b75430e"
            ],
            "layout": "IPY_MODEL_b6e90203703f4cd8ba5cf232c76008e0"
          }
        },
        "357d3079b4844247bad5d39e798ce775": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "386b41658f2344a28f30ed34622d6082": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "38b6ac27f54343558f52c2cdee5ea6c8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39ca7555e7ba44f69bb77d6100b926ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d62ba8c35db495ea60835edaf783fd6",
            "placeholder": "​",
            "style": "IPY_MODEL_46e756a51c334b61b5261df95f53e14d",
            "value": " 1.49k/? [00:00&lt;00:00, 78.5kB/s]"
          }
        },
        "39e46910b26f46b5a55e4f35ee39a1e4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3aa5a0ff6e0b479e80e61fab3f5f9676": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3ba7c11508a94c96979a67e158930074": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3ba995d0844e4021b04ce53220859861": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a33c26a0f9cd4153a8b47392ee26e8f4",
              "IPY_MODEL_93a2946af18d4a4ea41cbfe361662dec",
              "IPY_MODEL_23bc989e0f704d939f2f62d2f24fb49b"
            ],
            "layout": "IPY_MODEL_989faaafb22f4bb5b0801591920ce706"
          }
        },
        "3d62ba8c35db495ea60835edaf783fd6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3fc9567f67f44e2ba2e08e7093de2078": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c00a3d335554937902a3ce5df935a80",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e34ca5262ae64e9bac59c874cce0a540",
            "value": 1
          }
        },
        "46e756a51c334b61b5261df95f53e14d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4a22f6ce7e8349268755fabcdea55d99": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4e501b73b517455fbe67d194341d02de": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56de5bc65e074a3ca48ae3a56d79620f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "597f3f2785e54aebb5d23daedd0471f7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c6a021cb6804383bc93edbe6e51dabd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5d8f67da24814a6a85929912b6e7d071": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_386b41658f2344a28f30ed34622d6082",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_079f1fea2d6643d39e65ab9c875a9836",
            "value": 1
          }
        },
        "5d9f038a211243968dec6b3e0694b85e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e5dd491f4dc4f32ab812f9b3632cf5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_72466284ebc24768bd65e6616be3651d",
              "IPY_MODEL_79353e1d488a49deb5fd05eee79c71a2",
              "IPY_MODEL_6f3d27c42f0f4268b1fc124a129cba60"
            ],
            "layout": "IPY_MODEL_6b5802e78a81449cbd78c7cb2501bbb2"
          }
        },
        "632896e846634bcfafd2d74ac4463889": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c38af6b645c845cd9a2d52946c1f9589",
            "placeholder": "​",
            "style": "IPY_MODEL_b30fab3726a146fe8cc0493beebef08d",
            "value": "configuration_caduceus.py: "
          }
        },
        "64b3f8102b6143b09940e2197f903acf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39e46910b26f46b5a55e4f35ee39a1e4",
            "placeholder": "​",
            "style": "IPY_MODEL_d74e4b28da864819abe7644419a74959",
            "value": "modeling_caduceus.py: "
          }
        },
        "6ab10cfdf9cb4a0b839ed65f7a76fb10": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "6b5802e78a81449cbd78c7cb2501bbb2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c73d1c2473742c998cbd8af240ee3bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab08b599c0b7456dabe98ca0a4c034fa",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3ba7c11508a94c96979a67e158930074",
            "value": 1
          }
        },
        "6cba79b9e7bc4d388e6b9290fdbb3f14": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f3d27c42f0f4268b1fc124a129cba60": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f5836ecbf24432a8b8e6c67f2ebf6ce",
            "placeholder": "​",
            "style": "IPY_MODEL_22ad45bb35694c93836bff5dcb2fbcf9",
            "value": " 30.9M/30.9M [00:01&lt;00:00, 19.2MB/s]"
          }
        },
        "72466284ebc24768bd65e6616be3651d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80a94d57d85144ce998b7f2ec6821d2e",
            "placeholder": "​",
            "style": "IPY_MODEL_357d3079b4844247bad5d39e798ce775",
            "value": "model.safetensors: 100%"
          }
        },
        "749c3136972e4a2bb9c9cdaeac5e2dcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "79353e1d488a49deb5fd05eee79c71a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f41b505df9164a7bbfb6b022e7e2a1a1",
            "max": 30937760,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7eee2e4d99cc4ff9a750d8c2016aa892",
            "value": 30937760
          }
        },
        "7eed4d05343844598acae09492e616fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1cdc96b606114fab978179e29e18a07c",
            "placeholder": "​",
            "style": "IPY_MODEL_749c3136972e4a2bb9c9cdaeac5e2dcd",
            "value": "tokenizer_config.json: "
          }
        },
        "7eee2e4d99cc4ff9a750d8c2016aa892": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "804270ff740f43e29d033f2cbbbb407e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80a94d57d85144ce998b7f2ec6821d2e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84fc41e6bf8e45e58f20f80fe3e0cd5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1fab06d5e034b53a5a96574ba9f1c1a",
            "placeholder": "​",
            "style": "IPY_MODEL_a460f0e3dad842ab9252acc1a3d117c8",
            "value": " 1.96k/? [00:00&lt;00:00, 199kB/s]"
          }
        },
        "93a2946af18d4a4ea41cbfe361662dec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4ae89b22e7244aebcf11e2f875b9f14",
            "max": 173,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fc37c63dd6f44287ad57b78ac105ea86",
            "value": 173
          }
        },
        "96197a22254d4efdac6f6084a8d8b01c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "968f1cced68f4475b93814d853350883": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_632896e846634bcfafd2d74ac4463889",
              "IPY_MODEL_ecb767c23d1e48ed9e6b50162105ea0f",
              "IPY_MODEL_84fc41e6bf8e45e58f20f80fe3e0cd5b"
            ],
            "layout": "IPY_MODEL_4e501b73b517455fbe67d194341d02de"
          }
        },
        "989faaafb22f4bb5b0801591920ce706": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98a0bd916d0742b7b79e57fbe4a32a94": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_64b3f8102b6143b09940e2197f903acf",
              "IPY_MODEL_6c73d1c2473742c998cbd8af240ee3bf",
              "IPY_MODEL_222b409cafd84d828de35e91fa23328e"
            ],
            "layout": "IPY_MODEL_bba3c144cc0c41368113f407be2b84fa"
          }
        },
        "9f5836ecbf24432a8b8e6c67f2ebf6ce": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a33c26a0f9cd4153a8b47392ee26e8f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96197a22254d4efdac6f6084a8d8b01c",
            "placeholder": "​",
            "style": "IPY_MODEL_4a22f6ce7e8349268755fabcdea55d99",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "a460f0e3dad842ab9252acc1a3d117c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aaaa6f03a1bc46adb0b3d17eefaee3f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ab10cfdf9cb4a0b839ed65f7a76fb10",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_23d42eca961e45138f2fe9b9cfd469bd",
            "value": 1
          }
        },
        "ab08b599c0b7456dabe98ca0a4c034fa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "b30fab3726a146fe8cc0493beebef08d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b6e90203703f4cd8ba5cf232c76008e0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bba3c144cc0c41368113f407be2b84fa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bba6167f15df43b19b5364b1c3731293": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2e2c452b771402c9b51a17d53895af9",
            "placeholder": "​",
            "style": "IPY_MODEL_0bcd230a521144dd9a90b0a4e5804e18",
            "value": " 9.98k/? [00:00&lt;00:00, 896kB/s]"
          }
        },
        "bd0e5b6748a44e40aea1c06c56e835a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8d77670accb45bc8099d526ea611205",
            "placeholder": "​",
            "style": "IPY_MODEL_daa648b6aa254d148fbee6bbb836aad0",
            "value": "tokenization_caduceus.py: "
          }
        },
        "c12a1faedcfc4f7a8243153dc43debff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_04548c9f950b406f8c11399225bc6012",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3aa5a0ff6e0b479e80e61fab3f5f9676",
            "value": 1
          }
        },
        "c1c4f5d70e1246879fa2d76291f09096": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1fab06d5e034b53a5a96574ba9f1c1a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2e2c452b771402c9b51a17d53895af9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c38af6b645c845cd9a2d52946c1f9589": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c40459290ee141859ffa161bc29d7e44": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c8d77670accb45bc8099d526ea611205": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1644cd9dcb24ec2838396e681bec025": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fbcbe20cae3247dea61e7d080db29c6f",
              "IPY_MODEL_5d8f67da24814a6a85929912b6e7d071",
              "IPY_MODEL_d9069a4a66cc4429a1f5645fde994ed7"
            ],
            "layout": "IPY_MODEL_56de5bc65e074a3ca48ae3a56d79620f"
          }
        },
        "d296616dbdea44b486ba11d67d569bcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d74e4b28da864819abe7644419a74959": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d9069a4a66cc4429a1f5645fde994ed7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6cba79b9e7bc4d388e6b9290fdbb3f14",
            "placeholder": "​",
            "style": "IPY_MODEL_0e3b1ccb6dce4b069abfe5f50f065c3c",
            "value": " 1.38k/? [00:00&lt;00:00, 115kB/s]"
          }
        },
        "daa648b6aa254d148fbee6bbb836aad0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "de134ccb6cfe437190c92ab012f68873": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "e34ca5262ae64e9bac59c874cce0a540": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ecb767c23d1e48ed9e6b50162105ea0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de134ccb6cfe437190c92ab012f68873",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2d5ecc994062496a8df3b5c4b2d97d9a",
            "value": 1
          }
        },
        "ee14c46ccc4246d88d240df8512c1337": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f41b505df9164a7bbfb6b022e7e2a1a1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4ae89b22e7244aebcf11e2f875b9f14": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fbcbe20cae3247dea61e7d080db29c6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c1293e61e5e46288e15ede5f3a16cdd",
            "placeholder": "​",
            "style": "IPY_MODEL_5c6a021cb6804383bc93edbe6e51dabd",
            "value": "config.json: "
          }
        },
        "fc37c63dd6f44287ad57b78ac105ea86": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fc3d758a8f2e447da13c1ccf8b75430e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d9f038a211243968dec6b3e0694b85e",
            "placeholder": "​",
            "style": "IPY_MODEL_ee14c46ccc4246d88d240df8512c1337",
            "value": " 4.97k/? [00:00&lt;00:00, 506kB/s]"
          }
        },
        "fd0634a434604e9d8f287058331f5e2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_216ba280eb814703832293e3702de817",
              "IPY_MODEL_c12a1faedcfc4f7a8243153dc43debff",
              "IPY_MODEL_bba6167f15df43b19b5364b1c3731293"
            ],
            "layout": "IPY_MODEL_2538951b19554f77a43351ec10695b71"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
